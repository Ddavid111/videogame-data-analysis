{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "B3plUzUyAVjB",
    "outputId": "24047dae-f2bc-45c8-8c22-ef52e15fdfc3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-22 16:27:50] INFO: === Starting merge process ===\n",
      "[2025-10-22 16:27:50] INFO: Loaded: steam.csv (27075 rows)\n",
      "[2025-10-22 16:27:51] INFO: Loaded: steam_description_data.csv (27334 rows)\n",
      "[2025-10-22 16:27:52] INFO: Loaded: steam_media_data.csv (27332 rows)\n",
      "[2025-10-22 16:27:52] INFO: Loaded: steam_support_info.csv (27136 rows)\n",
      "[2025-10-22 16:27:53] INFO: Loaded: steamspy_tag_data.csv (29022 rows)\n",
      "[2025-10-22 16:27:53] INFO: Loaded: steam_requirements_data.csv (27319 rows)\n",
      "[2025-10-22 16:27:53] INFO: A source merged: 27075 rows\n",
      "[2025-10-22 16:28:11] INFO: B source loaded from JSON: 111452 rows\n",
      "[2025-10-22 16:28:23] INFO: B full DataFrame written to CSV\n",
      "[2025-10-22 16:28:31] INFO: Loaded: games_march2025_cleaned.csv (89618 rows)\n",
      "[2025-10-22 16:28:37] INFO: Loaded: games_march2025_full.csv (94948 rows)\n",
      "[2025-10-22 16:28:42] INFO: Loaded: games_may2024_cleaned.csv (83646 rows)\n",
      "[2025-10-22 16:28:47] INFO: Loaded: games_may2024_full.csv (87806 rows)\n",
      "[2025-10-22 16:28:47] INFO: C source combined: 356018 rows\n",
      "[2025-10-22 16:28:47] INFO: Merging sources with C→B→A priority...\n",
      "[2025-10-22 16:32:25] INFO: Merge complete (112855 rows, 434 columns)\n",
      "C:\\Users\\zalma\\AppData\\Local\\Temp\\ipykernel_8268\\133001455.py:428: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  D['categories_a'] = D['appid'].map(a.set_index('appid')['categories'])\n",
      "C:\\Users\\zalma\\AppData\\Local\\Temp\\ipykernel_8268\\133001455.py:430: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  D['categories_b'] = D['appid'].map(b.set_index('appid')['categories'])\n",
      "C:\\Users\\zalma\\AppData\\Local\\Temp\\ipykernel_8268\\133001455.py:432: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  D['categories_c'] = D['appid'].map(c.set_index('appid')['categories'])\n",
      "[2025-10-22 16:32:30] INFO: Normalized thumbnail screenshots for source A (27075 items)\n",
      "[2025-10-22 16:32:30] INFO: Normalized thumbnail screenshots for source B (111452 items)\n",
      "[2025-10-22 16:32:34] INFO: Normalized thumbnail screenshots for source C (104490 items)\n",
      "C:\\Users\\zalma\\AppData\\Local\\Temp\\ipykernel_8268\\133001455.py:437: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  D[\"screenshots_thumb\"] = D[\"appid\"].map(\n",
      "[2025-10-22 16:32:36] INFO: Normalized movies for source A (25393 items)\n",
      "[2025-10-22 16:32:37] INFO: Normalized movies for source B (111452 items)\n",
      "[2025-10-22 16:32:40] INFO: Normalized movies for source C (104490 items)\n",
      "C:\\Users\\zalma\\AppData\\Local\\Temp\\ipykernel_8268\\133001455.py:448: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  D[\"movies_thumbnail\"] = D[\"appid\"].map(lambda x: c_thumb_m.get(x, []) + b_thumb_m.get(x, []) + a_thumb_m.get(x, []))\n",
      "C:\\Users\\zalma\\AppData\\Local\\Temp\\ipykernel_8268\\133001455.py:449: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  D[\"movies_480\"] = D[\"appid\"].map(lambda x: c_480.get(x, []) + b_480.get(x, []) + a_480.get(x, []))\n",
      "C:\\Users\\zalma\\AppData\\Local\\Temp\\ipykernel_8268\\133001455.py:303: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  D[\"sources\"] = sources\n",
      "[2025-10-22 16:33:53] INFO: Merged master table saved to: C:\\Users\\zalma\\merge\\merged_master.csv\n",
      "[2025-10-22 16:33:53] INFO: === Merge process successfully completed ===\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Any\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# ======== PATHS ========\n",
    "BASE_PATH = r\"C:\\Users\\zalma\"\n",
    "A_PATH = os.path.join(BASE_PATH, \"A\")\n",
    "B_PATH = os.path.join(BASE_PATH, \"B\")\n",
    "C_PATH = os.path.join(BASE_PATH, \"C\")\n",
    "OUTPUT_PATH = os.path.join(BASE_PATH, \"merge\")\n",
    "\n",
    "# ======== LOGGING CONFIGURATION ========\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "LOG_FILE = os.path.join(OUTPUT_PATH, \"merge_log.txt\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"[%(asctime)s] %(levelname)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.FileHandler(LOG_FILE, encoding=\"utf-8\"), logging.StreamHandler()],\n",
    ")\n",
    "\n",
    "# ======== HELPER FUNCTIONS ========\n",
    "def load_csv_safely(path: str, **kwargs: Any) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Betölt egy CSV fájlt, hiba esetén üres DataFrame-et ad vissza.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path, **kwargs)\n",
    "        logging.info(f\"Loaded: {os.path.basename(path)} ({len(df)} rows)\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading {path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "def clean_columns(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardizálja a DataFrame oszlopneveit: levágja a szóközöket, kisbetűssé alakítja,\n",
    "    és helyettesíti a szóközöket és kötőjeleket alulvonással.\n",
    "    \"\"\"\n",
    "    df.columns = (\n",
    "        df.columns.str.strip().str.lower().str.replace(\" \", \"_\").str.replace(\"-\", \"_\")\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "def fill_missing_from_source(D: pd.DataFrame, src: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Kitölti a hiányzó értékeket a D DataFrame-ben egy forrás (src) adatai alapján.\n",
    "    Az appid oszlop alapján merge-öl, a közös oszlopokat balról tölti.\n",
    "    \"\"\"\n",
    "    src = src.copy()\n",
    "    src[\"appid\"] = src[\"appid\"].astype(str)\n",
    "\n",
    "    common_cols = [col for col in src.columns if col in D.columns]\n",
    "\n",
    "    merged = D.merge(\n",
    "        src[common_cols],\n",
    "        on=\"appid\",\n",
    "        how=\"left\",\n",
    "        suffixes=(\"\", \"_src\")\n",
    "    )\n",
    "\n",
    "    for col in common_cols:\n",
    "        if col != \"appid\":\n",
    "            merged[col] = merged[col].combine_first(merged[f\"{col}_src\"])\n",
    "            merged.drop(columns=[f\"{col}_src\"], inplace=True)\n",
    "\n",
    "    return merged\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ======== SOURCE LOADING FUNCTIONS ========\n",
    "def load_source_a(a_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Betölti az A forrást (Steam CSV fájlok), megtisztítja az oszlopneveket,\n",
    "    és merge-eli a különböző fájlokat egy DataFrame-be.\n",
    "    \"\"\"\n",
    "    steam = load_csv_safely(os.path.join(a_path, \"steam.csv\"))\n",
    "    description = load_csv_safely(os.path.join(a_path, \"steam_description_data.csv\"))\n",
    "    media = load_csv_safely(os.path.join(a_path, \"steam_media_data.csv\"))\n",
    "    support = load_csv_safely(os.path.join(a_path, \"steam_support_info.csv\"))\n",
    "    tags = load_csv_safely(os.path.join(a_path, \"steamspy_tag_data.csv\"))\n",
    "    reqs = load_csv_safely(os.path.join(a_path, \"steam_requirements_data.csv\"))\n",
    "\n",
    "    for df in [steam, description, media, support, tags, reqs]:\n",
    "        if not df.empty:\n",
    "            df = clean_columns(df)\n",
    "            possible_ids = [c for c in df.columns if \"appid\" in c.lower()]\n",
    "            if possible_ids:\n",
    "                df.rename(columns={possible_ids[0]: \"appid\"}, inplace=True)\n",
    "\n",
    "    merged = (\n",
    "        steam.merge(description, on=\"appid\", how=\"left\")\n",
    "        .merge(media, on=\"appid\", how=\"left\")\n",
    "        .merge(support, on=\"appid\", how=\"left\")\n",
    "        .merge(tags, on=\"appid\", how=\"left\")\n",
    "        .merge(reqs, on=\"appid\", how=\"left\")\n",
    "    )\n",
    "    logging.info(f\"A source merged: {len(merged)} rows\")\n",
    "    return merged\n",
    "\n",
    "\n",
    "def load_source_b(base_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Betölti a B forrást JSON fájlból, előkészíti Pandas DataFrame-re,\n",
    "    és beállítja a numerikus és logikai oszlopok típusait.\n",
    "    \"\"\"\n",
    "    file_path = os.path.join(base_path, \"games.json\")\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.error(f\"File not found: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        dataset = json.load(f)\n",
    "\n",
    "    records = []\n",
    "    for appID, game in dataset.items():\n",
    "        fields = [\n",
    "            \"name\",\n",
    "            \"release_date\",\n",
    "            \"estimated_owners\",\n",
    "            \"price\",\n",
    "            \"required_age\",\n",
    "            \"dlc_count\",\n",
    "            \"detailed_description\",\n",
    "            \"short_description\",\n",
    "            \"about_the_game\",\n",
    "            \"reviews\",\n",
    "            \"header_image\",\n",
    "            \"website\",\n",
    "            \"support_url\",\n",
    "            \"support_email\",\n",
    "            \"windows\",\n",
    "            \"mac\",\n",
    "            \"linux\",\n",
    "            \"metacritic_score\",\n",
    "            \"metacritic_url\",\n",
    "            \"user_score\",\n",
    "            \"positive\",\n",
    "            \"negative\",\n",
    "            \"score_rank\",\n",
    "            \"achievements\",\n",
    "            \"recommendations\",\n",
    "            \"notes\",\n",
    "            \"average_playtime_forever\",\n",
    "            \"average_playtime_2weeks\",\n",
    "            \"median_playtime_forever\",\n",
    "            \"median_playtime_2weeks\",\n",
    "            \"peak_ccu\",\n",
    "        ]\n",
    "\n",
    "        record = {key: game.get(key) for key in fields}\n",
    "        record[\"appid\"] = str(appID)\n",
    "\n",
    "        record[\"packages\"] = game.get(\"packages\", [])\n",
    "        record[\"developers\"] = game.get(\"developers\", [])\n",
    "        record[\"publishers\"] = game.get(\"publishers\", [])\n",
    "        record[\"categories\"] = game.get(\"categories\", [])\n",
    "        record[\"genres\"] = game.get(\"genres\", [])\n",
    "        record[\"supported_languages\"] = game.get(\"supported_languages\", [])\n",
    "        record[\"full_audio_languages\"] = game.get(\"full_audio_languages\", [])\n",
    "        record[\"screenshots\"] = game.get(\"screenshots\", [])\n",
    "        record[\"movies\"] = game.get(\"movies\", [])\n",
    "        tags = game.get(\"tags\", {})\n",
    "        if isinstance(tags, dict):\n",
    "            record[\"tags\"] = tags\n",
    "        else:\n",
    "            record[\"tags\"] = {}\n",
    "\n",
    "\n",
    "        records.append(record)\n",
    "\n",
    "    df_b = pd.DataFrame(records)\n",
    "\n",
    "    df_b_exploded = df_b.explode(\"packages\").dropna(subset=[\"packages\"])\n",
    "\n",
    "    numeric_cols = [\n",
    "        \"metacritic_score\",\n",
    "        \"user_score\",\n",
    "        \"positive\",\n",
    "        \"negative\",\n",
    "        \"achievements\",\n",
    "        \"recommendations\",\n",
    "        \"price\",\n",
    "        \"required_age\",\n",
    "        \"dlc_count\",\n",
    "        \"average_playtime_forever\",\n",
    "        \"average_playtime_2weeks\",\n",
    "        \"median_playtime_forever\",\n",
    "        \"median_playtime_2weeks\",\n",
    "        \"peak_ccu\",\n",
    "    ]\n",
    "    \n",
    "    packages_df = pd.json_normalize(df_b.explode(\"packages\")[\"packages\"])\n",
    "    \n",
    "    for col in numeric_cols:\n",
    "        if col in df_b.columns:\n",
    "            df_b[col] = pd.to_numeric(df_b[col], errors=\"coerce\")\n",
    "\n",
    "    bool_cols = [\"windows\", \"mac\", \"linux\"]\n",
    "    for col in bool_cols:\n",
    "        if col in df_b.columns:\n",
    "            df_b[col] = df_b[col].astype(bool)\n",
    "\n",
    "    logging.info(f\"B source loaded from JSON: {len(df_b)} rows\")\n",
    "    return df_b\n",
    "\n",
    "\n",
    "def load_source_c(c_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Betölti a C forrást több CSV fájlból, megtisztítja az oszlopneveket,\n",
    "    és egyesíti az adatokat egy DataFrame-be.\n",
    "    \"\"\"\n",
    "    c_files = [\n",
    "        \"games_march2025_cleaned.csv\",\n",
    "        \"games_march2025_full.csv\",\n",
    "        \"games_may2024_cleaned.csv\",\n",
    "        \"games_may2024_full.csv\",\n",
    "    ]\n",
    "    c_dfs = [load_csv_safely(os.path.join(c_path, f)) for f in c_files]\n",
    "    c_dfs = [clean_columns(df) for df in c_dfs if not df.empty]\n",
    "    df_c = pd.concat(c_dfs, ignore_index=True)\n",
    "    df_c[\"appid\"] = df_c[\"appid\"].astype(str)\n",
    "    logging.info(f\"C source combined: {len(df_c)} rows\")\n",
    "    return df_c\n",
    "\n",
    "\n",
    "# ======== MERGE FUNCTION ========\n",
    "def merge_sources(a: pd.DataFrame, b: pd.DataFrame, c: pd.DataFrame, columns_to_merge: list[str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Összefésüli az A, B, C forrásokat AppID alapján.\n",
    "    C → B → A prioritással tölti ki a hiányzó adatokat.\n",
    "\n",
    "    Paraméter:\n",
    "        columns_to_merge: ha meg van adva, csak ezeket az oszlopokat (és appid-t) mergeli.\n",
    "    \"\"\"\n",
    "    logging.info(\"Merging sources with C→B→A priority...\")\n",
    "\n",
    "    for df in [a, b, c]:\n",
    "        if not df.empty:\n",
    "            df[\"appid\"] = df[\"appid\"].astype(str).str.strip()\n",
    "            df.drop_duplicates(subset=\"appid\", inplace=True)\n",
    "\n",
    "    if columns_to_merge:\n",
    "        keep_cols = [\"appid\"] + [col for col in columns_to_merge if col in a.columns or col in b.columns or col in c.columns]\n",
    "        a = a[[col for col in keep_cols if col in a.columns]]\n",
    "        b = b[[col for col in keep_cols if col in b.columns]]\n",
    "        c = c[[col for col in keep_cols if col in c.columns]]\n",
    "        logging.info(f\"Using subset of columns for merge: {keep_cols}\")\n",
    "\n",
    "    columns = list(dict.fromkeys(\n",
    "        sum([df.columns.tolist() for df in [a, b, c] if not df.empty], [])\n",
    "    ))\n",
    "\n",
    "    all_appids = pd.concat([a[[\"appid\"]], b[[\"appid\"]], c[[\"appid\"]]], ignore_index=True).drop_duplicates()\n",
    "\n",
    "    D = pd.DataFrame(columns=columns)\n",
    "    D[\"appid\"] = all_appids[\"appid\"]\n",
    "\n",
    "    for src in [c, b, a]:\n",
    "        if not src.empty:\n",
    "            D = fill_missing_from_source(D, src)\n",
    "\n",
    "    logging.info(f\"Merge complete ({len(D)} rows, {len(columns)} columns)\")\n",
    "    return D\n",
    "\n",
    "\n",
    "\n",
    "def finalize_sources(D, a, b, c):\n",
    "    \"\"\"\n",
    "    Hozzáad egy 'sources' oszlopot a D (merged_master) DataFrame-hez,\n",
    "    ami jelzi, hogy a sor melyik eredeti datasetből származik.\n",
    "    \"\"\"\n",
    "    a_ids = set(a[\"appid\"]) if not a.empty else set()\n",
    "    b_ids = set(b[\"appid\"]) if not b.empty else set()\n",
    "    c_ids = set(c[\"appid\"]) if not c.empty else set()\n",
    "\n",
    "    sources = []\n",
    "    for appid in D[\"appid\"]:\n",
    "        src = []\n",
    "        if appid in c_ids:\n",
    "            src.append(\"C\")\n",
    "        if appid in b_ids:\n",
    "            src.append(\"B\")\n",
    "        if appid in a_ids:\n",
    "            src.append(\"A\")\n",
    "        sources.append(\",\".join(src))\n",
    "\n",
    "    D[\"sources\"] = sources\n",
    "    return D\n",
    "\n",
    "# ======== Segédfüggvények a normalizáláshoz ========\n",
    "def normalize_screenshots_column(df: pd.DataFrame, source_name: str):\n",
    "    \"\"\"\n",
    "    Kivonatolja a screenshots oszlopot (ha létezik) és visszaadja a thumbnail URL-eket.\n",
    "    Működik dict/list/str típusokra is.\n",
    "    \"\"\"\n",
    "    thumb_dict = {}\n",
    "\n",
    "    if \"screenshots\" not in df.columns:\n",
    "        return thumb_dict\n",
    "\n",
    "    for appid, val in df[[\"appid\", \"screenshots\"]].itertuples(index=False):\n",
    "        thumb_urls = []\n",
    "\n",
    "        if val is None:\n",
    "            continue\n",
    "        if isinstance(val, float) and np.isnan(val):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = ast.literal_eval(val) if isinstance(val, str) else val\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        if isinstance(data, list):\n",
    "            for item in data:\n",
    "                if isinstance(item, dict):\n",
    "                    thumb = item.get(\"path_thumbnail\") or item.get(\"thumb\")\n",
    "                    if thumb:\n",
    "                        thumb_urls.append(thumb.strip())\n",
    "                elif isinstance(item, str):\n",
    "                    pass\n",
    "\n",
    "        thumb_urls = [u for u in thumb_urls if isinstance(u, str) and u.startswith(\"http\")]\n",
    "        thumb_urls = list(dict.fromkeys(thumb_urls))\n",
    "\n",
    "        thumb_dict[str(appid)] = thumb_urls\n",
    "\n",
    "    logging.info(f\"Normalized thumbnail screenshots for source {source_name} ({len(thumb_dict)} items)\")\n",
    "    return thumb_dict\n",
    "\n",
    "def process_screenshots(a, b, c):\n",
    "    \"\"\"\n",
    "    Normalizálja a screenshots oszlopokat, \n",
    "    visszaadja a thumbnail dict-eket.\n",
    "    \"\"\"\n",
    "    a_thumb = normalize_screenshots_column(a, \"A\")\n",
    "    b_thumb = normalize_screenshots_column(b, \"B\")\n",
    "    c_thumb = normalize_screenshots_column(c, \"C\")\n",
    "    return a_thumb, b_thumb, c_thumb\n",
    "\n",
    "\n",
    "def normalize_movies_column(df: pd.DataFrame, source_name: str):\n",
    "    '''\n",
    "    Normalizálja a 'movies' oszlopot:\n",
    "    - movies_thumbnail: a 'thumbnail' URL-ek\n",
    "    - movies_480: a 'webm.480' URL-ek\n",
    "    - movies_max: a 'webm.max' URL-ek\n",
    "    '''\n",
    "    thumb_dict = {}\n",
    "    m480_dict = {}\n",
    "    mmax_dict = {}\n",
    "\n",
    "    if \"movies\" not in df.columns:\n",
    "        return thumb_dict, m480_dict, mmax_dict\n",
    "\n",
    "    for appid, val in df[[\"appid\", \"movies\"]].itertuples(index=False):\n",
    "        thumbs = []\n",
    "        webm_480 = []\n",
    "        webm_max = []\n",
    "\n",
    "        if val is None:\n",
    "            continue\n",
    "        if isinstance(val, float) and np.isnan(val):\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            data = ast.literal_eval(val) if isinstance(val, str) else val\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        if isinstance(data, list):\n",
    "            for item in data:\n",
    "                if isinstance(item, dict):\n",
    "                    t = item.get(\"thumbnail\")\n",
    "                    if t:\n",
    "                        thumbs.append(t.strip())\n",
    "                    w480 = item.get(\"webm\", {}).get(\"480\")\n",
    "                    if w480:\n",
    "                        webm_480.append(w480.strip())\n",
    "                    wmax = item.get(\"webm\", {}).get(\"max\")\n",
    "                    if wmax:\n",
    "                        webm_max.append(wmax.strip())\n",
    "\n",
    "        thumb_dict[str(appid)] = thumbs\n",
    "        m480_dict[str(appid)] = webm_480\n",
    "        mmax_dict[str(appid)] = mmax_dict.get(str(appid), []) + mmax_dict.get(str(appid), [])\n",
    "\n",
    "    logging.info(f\"Normalized movies for source {source_name} ({len(thumb_dict)} items)\")\n",
    "    return thumb_dict, m480_dict, mmax_dict\n",
    "\n",
    "def dedup_join(urls):\n",
    "    '''\n",
    "    Egy lista vagy tuple URL-t megtisztít duplikátumoktól és vesszővel összefűzi őket.\n",
    "    '''\n",
    "    if not urls or not isinstance(urls, (list, tuple)):\n",
    "        return \"\"\n",
    "    return \", \".join(list(dict.fromkeys(urls)))\n",
    "\n",
    "def merge_and_finalize(a: pd.DataFrame, b: pd.DataFrame, c: pd.DataFrame, columns_to_merge: list[str] = None) -> pd.DataFrame:\n",
    "    '''\n",
    "    Három forrás-DataFrame (A, B, C) egyesítése és véglegesítése.\n",
    "\n",
    "    - Merge-eli a forrásokat az `appid` alapján.\n",
    "    - Kategória-, screenshot- és videóadatokat egyesít és átnevez.\n",
    "    - Thumbnail és 480p videóoszlopokat hoz létre.\n",
    "    - Eltávolítja a duplikált URL-eket (`dedup_join` segítségével).\n",
    "    - Összevonja a fejlesztői, kiadói, kategória- és tag-információkat.\n",
    "    '''\n",
    "    D = merge_sources(a, b, c, columns_to_merge=columns_to_merge)\n",
    "\n",
    "    if 'categories' in a.columns:\n",
    "        D['categories_a'] = D['appid'].map(a.set_index('appid')['categories'])\n",
    "    if 'categories' in b.columns:\n",
    "        D['categories_b'] = D['appid'].map(b.set_index('appid')['categories'])\n",
    "    if 'categories' in c.columns:\n",
    "        D['categories_c'] = D['appid'].map(c.set_index('appid')['categories'])\n",
    "\n",
    "    if \"screenshots\" in D.columns:\n",
    "        D.rename(columns={\"screenshots\": \"screenshots_full\"}, inplace=True)\n",
    "    a_thumb, b_thumb, c_thumb = process_screenshots(a, b, c)\n",
    "    D[\"screenshots_thumb\"] = D[\"appid\"].map(\n",
    "        lambda x: c_thumb.get(x, []) + b_thumb.get(x, []) + a_thumb.get(x, [])\n",
    "    )\n",
    "\n",
    "    if \"movies\" in D.columns:\n",
    "        D.rename(columns={\"movies\": \"movies_max\"}, inplace=True)\n",
    "\n",
    "    a_thumb_m, a_480, a_max = normalize_movies_column(a, \"A\")\n",
    "    b_thumb_m, b_480, b_max = normalize_movies_column(b, \"B\")\n",
    "    c_thumb_m, c_480, c_max = normalize_movies_column(c, \"C\")\n",
    "\n",
    "    D[\"movies_thumbnail\"] = D[\"appid\"].map(lambda x: c_thumb_m.get(x, []) + b_thumb_m.get(x, []) + a_thumb_m.get(x, []))\n",
    "    D[\"movies_480\"] = D[\"appid\"].map(lambda x: c_480.get(x, []) + b_480.get(x, []) + a_480.get(x, []))\n",
    "        \n",
    "\n",
    "    for col in [\"screenshots_thumb\", \"movies_thumbnail\", \"movies_480\"]:\n",
    "        D[col] = D[col].apply(dedup_join)\n",
    "\n",
    "    D = finalize_sources(D, a, b, c)\n",
    "\n",
    "    D = merge_developers_publishers(D)\n",
    "    D = merge_categories(D)\n",
    "\n",
    "    tags_df = merge_tags_column(D, a, b, c)\n",
    "\n",
    "    tags_collapsed = (\n",
    "        tags_df.groupby(\"appid\")\n",
    "        .apply(lambda x: [{\"tag_name\": t, \"weight\": w} for t, w in zip(x[\"tag_name\"], x[\"weight\"])])\n",
    "        .reset_index(name=\"tags\")\n",
    "    )\n",
    "        \n",
    "    D = D.merge(tags_collapsed, on=\"appid\", how=\"left\")\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "\n",
    "def flatten_values(vals):\n",
    "    \"\"\"Lapítja a listákat / stringként tárolt listákat egy sima listává.\"\"\"\n",
    "    flat = []\n",
    "    for v in vals:\n",
    "        if isinstance(v, str):\n",
    "            v = v.strip()\n",
    "            if v.startswith(\"[\") and v.endswith(\"]\"):\n",
    "                try:\n",
    "                    sublist = ast.literal_eval(v)\n",
    "                    if isinstance(sublist, list):\n",
    "                        flat.extend([str(s).strip() for s in sublist if pd.notna(s)])\n",
    "                        continue\n",
    "                except Exception:\n",
    "                    pass\n",
    "        flat.append(str(v).strip())\n",
    "    return list(dict.fromkeys(flat))\n",
    "\n",
    "def combine_cols(row: pd.Series, cols: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Több oszlopból származó értékeket kombinál egyetlen, duplikátummentes stringgé.\n",
    "\n",
    "    - Kinyeri az értékeket a megadott oszlopokból.\n",
    "    - Támogatja a listákat, NumPy tömböket és skalárokat is.\n",
    "    - A duplikátumokat eltávolítja és vesszővel elválasztva adja vissza.\n",
    "    \"\"\"\n",
    "    vals = []\n",
    "    for col in cols:\n",
    "        val = row.get(col, None)\n",
    "        if val is None:\n",
    "            continue\n",
    "        if isinstance(val, (list, np.ndarray)):\n",
    "            vals.extend(flatten_values(val))\n",
    "        else:\n",
    "            vals.extend(flatten_values([val]))\n",
    "    return \", \".join(list(dict.fromkeys(vals)))\n",
    "\n",
    "\n",
    "def merge_developers_publishers(D: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Összevonja a fejlesztői és kiadói oszlopokat, eltávolítva a duplikált neveket.\n",
    "\n",
    "    - A 'developer' és 'developers' oszlopokból egyesített 'developers' oszlopot hoz létre.\n",
    "    - A 'publisher' és 'publishers' oszlopokból egyesített 'publishers' oszlopot hoz létre.\n",
    "    - Az eredeti ('developer', 'publisher') oszlopokat eltávolítja.\n",
    "    \"\"\"\n",
    "    D[\"developers\"] = D.apply(lambda row: combine_cols(row, [\"developer\", \"developers\"]), axis=1)\n",
    "    D[\"publishers\"] = D.apply(lambda row: combine_cols(row, [\"publisher\", \"publishers\"]), axis=1)\n",
    "\n",
    "    for col in [\"developer\", \"publisher\"]:\n",
    "        if col in D.columns:\n",
    "            D.drop(columns=[col], inplace=True)\n",
    "\n",
    "    return D\n",
    "\n",
    "def parse_categories(val) -> list[str]:\n",
    "    \"\"\"\n",
    "    Kategóriaértékek egységes listává alakítása.\n",
    "\n",
    "    - Kezeli a listákat, NumPy tömböket, stringeket és None értékeket.\n",
    "    - Tisztítja az üres vagy NaN értékeket.\n",
    "    - Felismeri a stringként tárolt listákat és a pontosvesszővel tagolt formátumokat.\n",
    "    \"\"\"\n",
    "    if val is None:\n",
    "        return []\n",
    "    if isinstance(val, (float, np.floating)) and np.isnan(val):\n",
    "        return []\n",
    "    if isinstance(val, (list, np.ndarray)):\n",
    "        return [str(v).strip() for v in val if isinstance(v, str) and v.strip()]\n",
    "    if isinstance(val, str):\n",
    "        val = val.strip()\n",
    "        if not val:\n",
    "            return []\n",
    "        if val.startswith(\"[\") and val.endswith(\"]\"):\n",
    "            try:\n",
    "                parsed = ast.literal_eval(val)\n",
    "                if isinstance(parsed, list):\n",
    "                    return [str(v).strip() for v in parsed if isinstance(v, str) and v.strip()]\n",
    "            except Exception:\n",
    "                pass\n",
    "        if \";\" in val:\n",
    "            return [v.strip() for v in val.split(\";\") if v.strip()]\n",
    "        return [val]\n",
    "    return []\n",
    "\n",
    "def combine_categories(row: pd.Series) -> str:\n",
    "    \"\"\"\n",
    "    Egy sor kategóriaoszlopait (A, B, C) kombinálja egyetlen, duplikátummentes stringgé.\n",
    "    \"\"\"\n",
    "    cats_a = parse_categories(row.get(\"categories_a\", row.get(\"categories\", None)))\n",
    "    cats_b = parse_categories(row.get(\"categories_b\", None))\n",
    "    cats_c = parse_categories(row.get(\"categories_c\", None))\n",
    "\n",
    "    merged = []\n",
    "    seen_lower = set()\n",
    "\n",
    "    for c in cats_a + cats_b + cats_c:\n",
    "        cl = c.lower()\n",
    "        if cl not in seen_lower:\n",
    "            merged.append(c)\n",
    "            seen_lower.add(cl)\n",
    "\n",
    "    return \", \".join(merged)\n",
    "\n",
    "def merge_categories(D: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    A források kategóriaoszlopait egyesíti egységes 'categories' oszlopba.\n",
    "\n",
    "    - A 'categories_a', 'categories_b', 'categories_c' oszlopokat kombinálja.\n",
    "    - Duplikátumokat kiszűri, kisbetű-érzéketlen módon.\n",
    "    - Eltávolítja a felesleges kategóriaoszlopokat.\n",
    "    \"\"\"\n",
    "    category_cols = [c for c in D.columns if \"categor\" in c.lower()]\n",
    "    D[\"categories\"] = D.apply(combine_categories, axis=1)\n",
    "\n",
    "    for col in category_cols:\n",
    "        if col != \"categories\":\n",
    "            D.drop(columns=[col], inplace=True, errors=\"ignore\")\n",
    "\n",
    "    return D\n",
    "\n",
    "\n",
    "def merge_tags_column(D: pd.DataFrame, a: pd.DataFrame, b: pd.DataFrame, c: pd.DataFrame) -> pd.DataFrame:\n",
    "    tags_a_dict = {}\n",
    "    if 'tags' in a.columns:\n",
    "        for appid, tags_str in zip(a['appid'], a['tags']):\n",
    "            if isinstance(tags_str, str):\n",
    "                tags_list = [t.strip() for t in tags_str.split(\",\") if t.strip()]\n",
    "                tags_a_dict[str(appid)] = {t: 1 for t in tags_list} \n",
    "\n",
    "    tags_b_dict = {}\n",
    "    if 'tags' in b.columns:\n",
    "        for appid, tags_json in zip(b['appid'], b['tags']):\n",
    "            if isinstance(tags_json, dict):\n",
    "                tags_b_dict[str(appid)] = tags_json\n",
    "\n",
    "    tags_c_dict = {}\n",
    "    if 'tags' in c.columns:\n",
    "        for appid, tags_str in zip(c['appid'], c['tags']):\n",
    "            if isinstance(tags_str, str):\n",
    "                try:\n",
    "                    tags_dict = ast.literal_eval(tags_str)\n",
    "                    if isinstance(tags_dict, dict):\n",
    "                        tags_c_dict[str(appid)] = tags_dict\n",
    "                except:\n",
    "                    continue\n",
    "\n",
    "    tag_rows = []\n",
    "    for appid in D['appid']:\n",
    "        tag_dict = {}\n",
    "        tag_dict.update(tags_a_dict.get(str(appid), {}))\n",
    "        tag_dict.update(tags_b_dict.get(str(appid), {}))\n",
    "        tag_dict.update(tags_c_dict.get(str(appid), {}))\n",
    "\n",
    "        for t, w in tag_dict.items():\n",
    "            tag_rows.append({\"appid\": appid, \"tag_name\": t, \"weight\": w})\n",
    "\n",
    "    tags_df = pd.DataFrame(tag_rows)\n",
    "    return tags_df\n",
    "\n",
    "\n",
    "def save_merged(D, path):\n",
    "    output_file = os.path.join(path, \"merged_master.csv\")\n",
    "    D.to_csv(output_file, index=False, encoding=\"utf-8\")\n",
    "    return output_file\n",
    "\n",
    "\n",
    "# ======== MAIN ========\n",
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    logging.info(\"=== Starting merge process ===\")\n",
    "    a = load_source_a(A_PATH)\n",
    "    a_output_file = os.path.join(OUTPUT_PATH, \"A_merged.csv\")\n",
    "    a.to_csv(a_output_file, index=False, encoding=\"utf-8\")\n",
    "\n",
    "    b = load_source_b(B_PATH)\n",
    "\n",
    "    b.to_csv(os.path.join(OUTPUT_PATH, \"B_full.csv\"), index=False, encoding=\"utf-8\")\n",
    "    logging.info(\"B full DataFrame written to CSV\")\n",
    "    \n",
    "    c = load_source_c(C_PATH)\n",
    "\n",
    "    D = merge_and_finalize(a, b, c)\n",
    "\n",
    "    output_file = save_merged(D, OUTPUT_PATH)\n",
    "    logging.info(f\"Merged master table saved to: {output_file}\")\n",
    "    \n",
    "    logging.info(\"=== Merge process successfully completed ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-22 16:48:10] INFO: === Starting splitting process ===\n",
      "C:\\Users\\zalma\\AppData\\Local\\Temp\\ipykernel_8268\\106111422.py:37: DtypeWarning: Columns (4,8,14,21,397,398,399,400,401,405,406,407,432,433,434) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(path, **kwargs)\n",
      "[2025-10-22 16:48:21] INFO: Loaded: merged_master.csv (112855 rows)\n",
      "[2025-10-22 16:48:21] INFO: Saved 'media.csv' (112855 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:48:25] INFO: Saved 'screenshots.csv' (112855 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:48:25] INFO: Saved 'movies.csv' (112771 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:48:26] INFO: Saved 'support.csv' (105409 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:49:16] INFO: Saved 'requirements.csv' (72365 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:49:24] INFO: Saved 'platforms.csv' (112855 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:49:24] INFO: Saved 'game_platform.csv' (112855 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:49:38] INFO: Saved game_package.csv (88410 rows)\n",
      "[2025-10-22 16:49:38] INFO: Saved packages.csv (88410 rows)\n",
      "[2025-10-22 16:49:38] INFO: Saved sub_package.csv (93939 rows)\n",
      "[2025-10-22 16:49:46] INFO: Saved 'developers.csv' (106337 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:49:46] INFO: Saved 'game_developer.csv' (106337 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:49:55] INFO: Saved 'publishers.csv' (106868 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:49:55] INFO: Saved 'game_publisher.csv' (106868 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:50:02] INFO: Saved 'genres.csv' (106341 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:50:02] INFO: Saved 'game_genre.csv' (106341 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:50:10] INFO: Saved 'categories.csv' (112855 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:50:10] INFO: Saved 'game_category.csv' (112855 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:50:30] INFO: Saved 'game_tag.csv' (1173669 rows) to C:\\Users\\zalma\\split\n",
      "[2025-10-22 16:50:30] INFO: Saved 'tags.csv' (1173669 rows) to C:\\Users\\zalma\\split\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "import ast\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from typing import Any\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import sys\n",
    "\n",
    "# ======== PATHS ========\n",
    "BASE_PATH = r\"C:\\Users\\zalma\"\n",
    "D_PATH = os.path.join(BASE_PATH, \"merge\")\n",
    "OUTPUT_PATH = os.path.join(BASE_PATH, \"split\")\n",
    "\n",
    "# ======== LOGGING CONFIGURATION ========\n",
    "os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "LOG_FILE = os.path.join(OUTPUT_PATH, \"merge_log.txt\")\n",
    "\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"[%(asctime)s] %(levelname)s: %(message)s\",\n",
    "    datefmt=\"%Y-%m-%d %H:%M:%S\",\n",
    "    handlers=[logging.FileHandler(LOG_FILE, encoding=\"utf-8\"), logging.StreamHandler()],\n",
    ")\n",
    "\n",
    "# ======== HELPER FUNCTIONS ========\n",
    "def load_csv_safely(path: str, **kwargs: Any) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Betölt egy CSV fájlt, hiba esetén üres DataFrame-et ad vissza.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path, **kwargs)\n",
    "        logging.info(f\"Loaded: {os.path.basename(path)} ({len(df)} rows)\")\n",
    "        return df\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error loading {path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "\n",
    "# ======== Segédfüggvények a splittelt táblákhoz ========\n",
    "def create_media_table(master_df: pd.DataFrame, output_dir: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Létrehozza a media táblát a merged_master-ből.\n",
    "    \n",
    "    \"\"\"\n",
    "    media_cols = [\"appid\", \"header_image\"]\n",
    "    media_df = master_df[[c for c in media_cols if c in master_df.columns]].copy()\n",
    "    \n",
    "    media_df = media_df.dropna(subset=[\"header_image\"]).reset_index(drop=True)\n",
    "    \n",
    "    media_df.insert(0, \"mediaid\", range(1, len(media_df)+1))\n",
    "    \n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        path = os.path.join(output_dir, \"media.csv\")\n",
    "        media_df.to_csv(path, index=False)\n",
    "        logging.info(f\"Saved 'media.csv' ({len(media_df)} rows) to {output_dir}\")\n",
    "    \n",
    "    return media_df\n",
    "\n",
    "def join_urls(x) -> str:\n",
    "    \"\"\"\n",
    "    Lista vagy string URL-eket egységes, vesszővel elválasztott stringgé alakít.\n",
    "\n",
    "    - Ha lista, akkor elemeit összefűzi ', ' elválasztóval.\n",
    "    - Ha már string, változatlanul visszaadja.\n",
    "    - Egyéb esetben üres stringet ad vissza.\n",
    "    \"\"\"\n",
    "    if isinstance(x, list):\n",
    "        return \", \".join(x)\n",
    "    elif isinstance(x, str):\n",
    "        return x\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def create_screenshots_table(master_df: pd.DataFrame, output_dir: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Létrehozza a screenshots táblát a master DataFrame-ből.\n",
    "\n",
    "    - Kiválasztja az 'appid', 'screenshots_full' és 'screenshots_thumb' oszlopokat.\n",
    "    - A listákat stringgé alakítja (`join_urls` segítségével).\n",
    "    - Eltávolítja az üres sorokat.\n",
    "    - Hozzáad egy automatikus 'screenshotid' azonosítót.\n",
    "    - CSV-fájlba menti az eredményt.\n",
    "    \"\"\"\n",
    "    cols = [\"appid\"]\n",
    "    for c in [\"screenshots_full\", \"screenshots_thumb\"]:\n",
    "        if c in master_df.columns:\n",
    "            cols.append(c)\n",
    "\n",
    "    df = master_df[cols].copy()\n",
    "\n",
    "    for c in [\"screenshots_full\", \"screenshots_thumb\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].apply(join_urls)\n",
    "\n",
    "    df = df[\n",
    "        (df.get(\"screenshots_full\", \"\") != \"\") |\n",
    "        (df.get(\"screenshots_thumb\", \"\") != \"\")\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    df.insert(0, \"screenshotid\", range(1, len(df) + 1))\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        path = os.path.join(output_dir, \"screenshots.csv\")\n",
    "        df.to_csv(path, index=False)\n",
    "        logging.info(f\"Saved 'screenshots.csv' ({len(df)} rows) to {output_dir}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def create_movies_table(master_df: pd.DataFrame, output_dir: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Létrehozza a 'movies' táblát a master DataFrame-ből.\n",
    "\n",
    "    - Kiválasztja az 'appid', 'movies_max', 'movies_thumbnail' és 'movies_480' oszlopokat.\n",
    "    - A listákat stringgé alakítja (`join_urls` segítségével).\n",
    "    - Csak azokat a sorokat tartja meg, ahol legalább egy URL szerepel.\n",
    "    - Hozzáad egy automatikus 'movieid' azonosítót.\n",
    "    - (Opcionálisan) CSV-fájlba menti az eredményt.\n",
    "\n",
    "    Visszatér: a videókat tartalmazó DataFrame.\n",
    "    \"\"\"\n",
    "    cols = [\"appid\"]\n",
    "    for c in [\"movies_max\", \"movies_thumbnail\", \"movies_480\"]:\n",
    "        if c in master_df.columns:\n",
    "            cols.append(c)\n",
    "\n",
    "    df = master_df[cols].copy()\n",
    "\n",
    "    for c in [\"movies_max\", \"movies_thumbnail\", \"movies_480\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].apply(join_urls)\n",
    "\n",
    "    # Csak azok maradjanak, ahol legalább egy oszlop nem üres\n",
    "    df = df[\n",
    "        (df.get(\"movies_max\", \"\") != \"\") |\n",
    "        (df.get(\"movies_thumbnail\", \"\") != \"\") |\n",
    "        (df.get(\"movies_480\", \"\") != \"\")\n",
    "    ].reset_index(drop=True)\n",
    "\n",
    "    df.insert(0, \"movieid\", range(1, len(df) + 1))\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        path = os.path.join(output_dir, \"movies.csv\")\n",
    "        df.to_csv(path, index=False)\n",
    "        logging.info(f\"Saved 'movies.csv' ({len(df)} rows) to {output_dir}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def create_support_table(master_df: pd.DataFrame, output_dir: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Létrehozza a support táblát a merged_master-ből.\n",
    "    Tartalmazza:\n",
    "      - supportid (1-től generált)\n",
    "      - appid\n",
    "      - support_url\n",
    "      - support_email\n",
    "    \"\"\"\n",
    "    cols = [\"appid\"]\n",
    "    for c in [\"support_url\", \"support_email\"]:\n",
    "        if c in master_df.columns:\n",
    "            cols.append(c)\n",
    "\n",
    "    df = master_df[cols].copy()\n",
    "\n",
    "    for c in [\"support_url\", \"support_email\"]:\n",
    "        if c in df.columns:\n",
    "            df[c] = df[c].fillna(\"\").astype(str)\n",
    "\n",
    "    df = df[(df.get(\"support_url\", \"\") != \"\") | (df.get(\"support_email\", \"\") != \"\")].reset_index(drop=True)\n",
    "\n",
    "    df.insert(0, \"supportid\", range(1, len(df) + 1))\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        path = os.path.join(output_dir, \"support.csv\")\n",
    "        df.to_csv(path, index=False)\n",
    "        logging.info(f\"Saved 'support.csv' ({len(df)} rows) to {output_dir}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_requirements_text(text):\n",
    "    if not text or pd.isna(text):\n",
    "        return \"\"\n",
    "    soup = BeautifulSoup(str(text), \"html.parser\")\n",
    "\n",
    "    for br in soup.find_all(\"br\"):\n",
    "        br.replace_with(\" \")\n",
    "\n",
    "    for li in soup.find_all(\"li\"):\n",
    "        li.replace_with(f\"{li.get_text()}, \")\n",
    "\n",
    "    cleaned = soup.get_text(separator=\" \").strip()\n",
    "\n",
    "    cleaned = re.sub(r'\\s+', ' ', cleaned)\n",
    "\n",
    "    cleaned = re.sub(r',\\s*$', '', cleaned)\n",
    "\n",
    "    cleaned = re.sub(r'^[\\)\\(\"\\'\\s,]+', '', cleaned)\n",
    "\n",
    "    cleaned = re.sub(r'(?i)^(minimum|recommended)[:\\s-]*', '', cleaned).strip()\n",
    "\n",
    "    return cleaned\n",
    "\n",
    "\n",
    "def split_min_rec(text):\n",
    "    \"\"\"\n",
    "    Szétválasztja a minimum és recommended részt a stringből.\n",
    "    Kis-/nagybetűt normalizál, ha a minimumban benne van a recommended, szétvágja.\n",
    "    \"\"\"\n",
    "    if not text or pd.isna(text):\n",
    "        return \"\", \"\"\n",
    "    text = str(text).strip()\n",
    "    parts = re.split(r\"(?i)Recommended[:\\s]*\", text, maxsplit=1)\n",
    "    min_part = parts[0].strip() if parts else \"\"\n",
    "    rec_part = parts[1].strip() if len(parts) > 1 else \"\"\n",
    "    return min_part, rec_part\n",
    "\n",
    "\n",
    "def create_requirements_table(master_df: pd.DataFrame, output_dir: str = None) -> pd.DataFrame:\n",
    "    rows = []\n",
    "\n",
    "    for _, r in master_df.iterrows():\n",
    "        appid = r['appid']\n",
    "\n",
    "        # --- Windows (pc_requirements) ---\n",
    "        pc_val = r.get('pc_requirements', \"\")\n",
    "        if pd.notna(pc_val) and str(pc_val).strip():\n",
    "            try:\n",
    "                val_dict = ast.literal_eval(pc_val)\n",
    "                win_min = clean_requirements_text(val_dict.get('minimum', \"\"))\n",
    "                win_rec = clean_requirements_text(val_dict.get('recommended', \"\"))\n",
    "            except Exception:\n",
    "                text = clean_requirements_text(pc_val)\n",
    "                win_min, win_rec = split_min_rec(text)\n",
    "\n",
    "            if win_min:\n",
    "                win_min, extra_rec = split_min_rec(win_min)\n",
    "                if win_min:\n",
    "                    rows.append({'appid': appid, 'os': 'windows', 'type': 'minimum', 'requirements': win_min})\n",
    "                if extra_rec:\n",
    "                    rows.append({'appid': appid, 'os': 'windows', 'type': 'recommended', 'requirements': extra_rec})\n",
    "\n",
    "            if win_rec:\n",
    "                rows.append({'appid': appid, 'os': 'windows', 'type': 'recommended', 'requirements': win_rec})\n",
    "\n",
    "\n",
    "        # --- Mac ---\n",
    "        val = r.get('mac_requirements', \"\")\n",
    "        if pd.notna(val):\n",
    "            val_str = str(val).strip()\n",
    "            if val_str and val_str not in [\"[]\", \"{}\", \"nan\", \"None\"]:\n",
    "                try:\n",
    "                    val_dict = ast.literal_eval(val)\n",
    "                    min_val = val_dict.get('minimum', \"\")\n",
    "                    rec_val = val_dict.get('recommended', \"\")\n",
    "                except Exception:\n",
    "                    min_val = val\n",
    "                    rec_val = \"\"\n",
    "\n",
    "                min_val = clean_requirements_text(min_val)\n",
    "                rec_val = clean_requirements_text(rec_val)\n",
    "\n",
    "                if min_val:\n",
    "                    min_val, extra_rec = split_min_rec(min_val)\n",
    "                    if min_val:\n",
    "                        rows.append({'appid': appid, 'os': 'mac', 'type': 'minimum', 'requirements': min_val})\n",
    "                    if extra_rec:\n",
    "                        rows.append({'appid': appid, 'os': 'mac', 'type': 'recommended', 'requirements': extra_rec})\n",
    "                if rec_val:\n",
    "                    rows.append({'appid': appid, 'os': 'mac', 'type': 'recommended', 'requirements': rec_val})\n",
    "\n",
    "        # --- Linux ---\n",
    "        val = r.get('linux_requirements', \"\")\n",
    "        if pd.notna(val):\n",
    "            val_str = str(val).strip()\n",
    "            if val_str and val_str not in [\"[]\", \"{}\", \"nan\", \"None\"]:\n",
    "                try:\n",
    "                    val_dict = ast.literal_eval(val)\n",
    "                    min_val = val_dict.get('minimum', \"\")\n",
    "                    rec_val = val_dict.get('recommended', \"\")\n",
    "                except Exception:\n",
    "                    min_val = val\n",
    "                    rec_val = \"\"\n",
    "\n",
    "                min_val = clean_requirements_text(min_val)\n",
    "                rec_val = clean_requirements_text(rec_val)\n",
    "\n",
    "                if min_val:\n",
    "                    min_val, extra_rec = split_min_rec(min_val)\n",
    "                    if min_val:\n",
    "                        rows.append({'appid': appid, 'os': 'linux', 'type': 'minimum', 'requirements': min_val})\n",
    "                    if extra_rec:\n",
    "                        rows.append({'appid': appid, 'os': 'linux', 'type': 'recommended', 'requirements': extra_rec})\n",
    "                if rec_val:\n",
    "                    rows.append({'appid': appid, 'os': 'linux', 'type': 'recommended', 'requirements': rec_val})\n",
    "\n",
    "\n",
    "\n",
    "    df_req = pd.DataFrame(rows)\n",
    "    if not df_req.empty:\n",
    "        df_req.insert(0, 'reqid', range(1, len(df_req)+1))\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        path = os.path.join(output_dir, \"requirements.csv\")\n",
    "        df_req.to_csv(path, index=False)\n",
    "        logging.info(f\"Saved 'requirements.csv' ({len(df_req)} rows) to {output_dir}\")\n",
    "\n",
    "    return df_req\n",
    "\n",
    "\n",
    "def create_genres_flat(master_df: pd.DataFrame, output_dir: str = None):\n",
    "    \"\"\"\n",
    "    Létrehozza a game_genre és genres táblákat:\n",
    "    - game_genre: appid + genreid\n",
    "    - genres: genreid + genre_name (eredeti genres mező)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for _, row in master_df.iterrows():\n",
    "        appid = row[\"appid\"]\n",
    "        genres_raw = row.get(\"genres\", \"\")\n",
    "\n",
    "        text = str(genres_raw).strip()\n",
    "        if text in [\"\", \"[]\", \"['']\"]:\n",
    "            continue\n",
    "\n",
    "        rows.append({\"appid\": appid, \"genre_name\": text})\n",
    "\n",
    "    df_flat = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    df_flat.insert(1, \"genreid\", range(1, len(df_flat)+1))\n",
    "\n",
    "    game_genre_df = df_flat[['appid', 'genreid']].copy()\n",
    "    genres_df = df_flat[['genreid', 'genre_name']].copy()\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        genres_path = os.path.join(output_dir, \"genres.csv\")\n",
    "        game_genre_path = os.path.join(output_dir, \"game_genre.csv\")\n",
    "        genres_df.to_csv(genres_path, index=False)\n",
    "        game_genre_df.to_csv(game_genre_path, index=False)\n",
    "        logging.info(f\"Saved 'genres.csv' ({len(genres_df)} rows) to {output_dir}\")\n",
    "        logging.info(f\"Saved 'game_genre.csv' ({len(game_genre_df)} rows) to {output_dir}\")\n",
    "\n",
    "    return genres_df, game_genre_df\n",
    "\n",
    "def create_platforms_flat(master_df: pd.DataFrame, output_dir: str = None):\n",
    "    \"\"\"\n",
    "    Létrehozza a game_platform és platforms táblákat:\n",
    "    - game_platform: appid + platid\n",
    "    - platforms: platid + windows/linux/mac logikai mezők\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for _, row in master_df.iterrows():\n",
    "        appid = row[\"appid\"]\n",
    "        windows = bool(row.get(\"windows\", False))\n",
    "        linux = bool(row.get(\"linux\", False))\n",
    "        mac = bool(row.get(\"mac\", False))\n",
    "\n",
    "        rows.append({\n",
    "            \"appid\": appid,\n",
    "            \"windows\": windows,\n",
    "            \"linux\": linux,\n",
    "            \"mac\": mac\n",
    "        })\n",
    "\n",
    "    df_flat = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    df_flat.insert(1, \"platid\", range(1, len(df_flat)+1))\n",
    "\n",
    "    game_platform_df = df_flat[['appid', 'platid']].copy()\n",
    "    platforms_df = df_flat[['platid', 'windows', 'linux', 'mac']].copy()\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        platforms_path = os.path.join(output_dir, \"platforms.csv\")\n",
    "        game_platform_path = os.path.join(output_dir, \"game_platform.csv\")\n",
    "        platforms_df.to_csv(platforms_path, index=False)\n",
    "        game_platform_df.to_csv(game_platform_path, index=False)\n",
    "        logging.info(f\"Saved 'platforms.csv' ({len(platforms_df)} rows) to {output_dir}\")\n",
    "        logging.info(f\"Saved 'game_platform.csv' ({len(game_platform_df)} rows) to {output_dir}\")\n",
    "\n",
    "    return platforms_df, game_platform_df\n",
    "\n",
    "def clean_packages(master_df: pd.DataFrame, output_dir: str):\n",
    "    rows_game_package = []\n",
    "    rows_packages = []\n",
    "    rows_sub_package = []\n",
    "\n",
    "    packid_counter = 1\n",
    "\n",
    "    for _, row in master_df.iterrows():\n",
    "        appid = row[\"appid\"]\n",
    "        packages_raw = row.get(\"packages\", \"\")\n",
    "\n",
    "        if pd.isna(packages_raw) or not str(packages_raw).strip():\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            packages_list = ast.literal_eval(packages_raw)\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        if not isinstance(packages_list, list):\n",
    "            continue\n",
    "\n",
    "        for pkg in packages_list:\n",
    "            title = pkg.get(\"title\", \"\").strip()\n",
    "            description = pkg.get(\"description\", \"\").strip()\n",
    "\n",
    "            if not title:\n",
    "                continue\n",
    "\n",
    "            rows_game_package.append({\"appid\": appid, \"packid\": packid_counter})\n",
    "\n",
    "            rows_packages.append({\"packid\": packid_counter, \"title\": title, \"description\": description})\n",
    "\n",
    "            subs = pkg.get(\"subs\", [])\n",
    "            for sub in subs:\n",
    "                sub_text = sub.get(\"text\", \"\").strip()\n",
    "                price = sub.get(\"price\", None)\n",
    "                rows_sub_package.append({\"packid\": packid_counter, \"sub_text\": sub_text, \"price\": price})\n",
    "\n",
    "            packid_counter += 1\n",
    "\n",
    "    df_game_package = pd.DataFrame(rows_game_package)\n",
    "    df_packages = pd.DataFrame(rows_packages)\n",
    "    df_sub_package = pd.DataFrame(rows_sub_package)\n",
    "\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    df_game_package.to_csv(os.path.join(output_dir, \"game_package.csv\"), index=False)\n",
    "    df_packages.to_csv(os.path.join(output_dir, \"packages.csv\"), index=False)\n",
    "    df_sub_package.to_csv(os.path.join(output_dir, \"sub_package.csv\"), index=False)\n",
    "\n",
    "    logging.info(f\"Saved game_package.csv ({len(df_game_package)} rows)\")\n",
    "    logging.info(f\"Saved packages.csv ({len(df_packages)} rows)\")\n",
    "    logging.info(f\"Saved sub_package.csv ({len(df_sub_package)} rows)\")\n",
    "\n",
    "    return df_game_package, df_packages, df_sub_package\n",
    "\n",
    "def create_developer_tables(master_df: pd.DataFrame, output_dir: str = None):\n",
    "    \"\"\"\n",
    "    Létrehozza a developers és game_developer táblákat úgy,\n",
    "    hogy minden játékhoz egy sor tartozik, még ha több fejlesztője is van.\n",
    "    - game_developer: appid + devid (1-től generált)\n",
    "    - developers: devid + name (összefűzött fejlesztők)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for _, row in master_df.iterrows():\n",
    "        appid = row[\"appid\"]\n",
    "        devs_raw = row.get(\"developers\", \"\")\n",
    "        if not devs_raw or pd.isna(devs_raw):\n",
    "            continue\n",
    "        \n",
    "        if isinstance(devs_raw, list):\n",
    "            dev_list = [str(d).strip() for d in devs_raw if str(d).strip()]\n",
    "        else:\n",
    "            dev_list = [d.strip() for d in str(devs_raw).split(\",\") if d.strip()]\n",
    "\n",
    "        if not dev_list:\n",
    "            continue\n",
    "        \n",
    "        combined_devs = \", \".join(dev_list)\n",
    "        rows.append({\"appid\": appid, \"developer_name\": combined_devs})\n",
    "\n",
    "    df_flat = pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "    df_flat.insert(1, \"devid\", range(1, len(df_flat)+1))\n",
    "\n",
    "    game_developer_df = df_flat[['appid', 'devid']].copy()\n",
    "    developers_df = df_flat[['devid', 'developer_name']].copy()\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        developers_path = os.path.join(output_dir, \"developers.csv\")\n",
    "        game_developer_path = os.path.join(output_dir, \"game_developer.csv\")\n",
    "        developers_df.to_csv(developers_path, index=False)\n",
    "        game_developer_df.to_csv(game_developer_path, index=False)\n",
    "        logging.info(f\"Saved 'developers.csv' ({len(developers_df)} rows) to {output_dir}\")\n",
    "        logging.info(f\"Saved 'game_developer.csv' ({len(game_developer_df)} rows) to {output_dir}\")\n",
    "\n",
    "    return developers_df, game_developer_df\n",
    "\n",
    "def create_publisher_tables(master_df: pd.DataFrame, output_dir: str = None):\n",
    "    \"\"\"\n",
    "    Létrehozza a publishers és game_publisher táblákat úgy,\n",
    "    hogy minden játékhoz egy sor tartozik, még ha több kiadója is van.\n",
    "    - game_publisher: appid + pubid (1-től generált)\n",
    "    - publishers: pubid + name (összefűzött kiadók)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for _, row in master_df.iterrows():\n",
    "        appid = row[\"appid\"]\n",
    "        pubs_raw = row.get(\"publishers\", \"\")\n",
    "        if not pubs_raw or pd.isna(pubs_raw):\n",
    "            continue\n",
    "        \n",
    "        if isinstance(pubs_raw, list):\n",
    "            pub_list = [str(p).strip() for p in pubs_raw if str(p).strip()]\n",
    "        else:\n",
    "            pub_list = [p.strip() for p in str(pubs_raw).split(\",\") if p.strip()]\n",
    "\n",
    "        if not pub_list:\n",
    "            continue\n",
    "        \n",
    "        combined_pubs = \", \".join(pub_list)\n",
    "        rows.append({\"appid\": appid, \"publisher_name\": combined_pubs})\n",
    "\n",
    "    df_flat = pd.DataFrame(rows).reset_index(drop=True)\n",
    "\n",
    "    df_flat.insert(1, \"pubid\", range(1, len(df_flat)+1))\n",
    "\n",
    "    game_publisher_df = df_flat[['appid', 'pubid']].copy()\n",
    "    publishers_df = df_flat[['pubid', 'publisher_name']].copy()\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        publishers_path = os.path.join(output_dir, \"publishers.csv\")\n",
    "        game_publisher_path = os.path.join(output_dir, \"game_publisher.csv\")\n",
    "        publishers_df.to_csv(publishers_path, index=False)\n",
    "        game_publisher_df.to_csv(game_publisher_path, index=False)\n",
    "        logging.info(f\"Saved 'publishers.csv' ({len(publishers_df)} rows) to {output_dir}\")\n",
    "        logging.info(f\"Saved 'game_publisher.csv' ({len(game_publisher_df)} rows) to {output_dir}\")\n",
    "\n",
    "    return publishers_df, game_publisher_df\n",
    "\n",
    "def create_categories_flat(master_df: pd.DataFrame, output_dir: str = None):\n",
    "    \"\"\"\n",
    "    Létrehozza a game_category és categories táblákat:\n",
    "    - game_category: appid + catid\n",
    "    - categories: catid + name (eredeti categories mező)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "\n",
    "    for _, row in master_df.iterrows():\n",
    "        appid = row[\"appid\"]\n",
    "        categories_raw = row.get(\"categories\", \"\")\n",
    "\n",
    "        text = str(categories_raw).strip()\n",
    "        if text in [\"\", \"[]\", \"['']\"]:\n",
    "            continue\n",
    "\n",
    "        rows.append({\"appid\": appid, \"name\": text})\n",
    "\n",
    "    df_flat = pd.DataFrame(rows).drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    df_flat.insert(1, \"catid\", range(1, len(df_flat)+1))\n",
    "\n",
    "    game_category_df = df_flat[['appid', 'catid']].copy()\n",
    "    categories_df = df_flat[['catid', 'name']].copy()\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        categories_path = os.path.join(output_dir, \"categories.csv\")\n",
    "        game_category_path = os.path.join(output_dir, \"game_category.csv\")\n",
    "        categories_df.to_csv(categories_path, index=False)\n",
    "        game_category_df.to_csv(game_category_path, index=False)\n",
    "        logging.info(f\"Saved 'categories.csv' ({len(categories_df)} rows) to {output_dir}\")\n",
    "        logging.info(f\"Saved 'game_category.csv' ({len(game_category_df)} rows) to {output_dir}\")\n",
    "\n",
    "    return categories_df, game_category_df\n",
    "\n",
    "\n",
    "def create_tags_flat(master_df: pd.DataFrame, output_dir: str = None):\n",
    "    rows_game_tag = []\n",
    "    rows_tags = []\n",
    "    tagid_counter = 1\n",
    "\n",
    "    for _, row in master_df.iterrows():\n",
    "        appid = row[\"appid\"]\n",
    "        tags_json = row.get(\"tags_x\") or row.get(\"tags_y\") or \"[]\"\n",
    "\n",
    "        if not tags_json or pd.isna(tags_json) or tags_json in [\"[]\", \"{}\"]:\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            if isinstance(tags_json, str):\n",
    "                tags_eval = ast.literal_eval(tags_json)\n",
    "            elif isinstance(tags_json, dict):\n",
    "                tags_eval = tags_json\n",
    "            elif isinstance(tags_json, list):\n",
    "                tags_eval = tags_json\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            if isinstance(tags_eval, dict):\n",
    "                tags_list = [{\"tag_name\": k, \"weight\": v} for k, v in tags_eval.items()]\n",
    "            elif isinstance(tags_eval, list):\n",
    "                tags_list = tags_eval\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "\n",
    "            for t in tags_list:\n",
    "                if isinstance(t, dict) and \"tag_name\" in t and \"weight\" in t:\n",
    "                    rows_game_tag.append({\"appid\": appid, \"tagid\": tagid_counter})\n",
    "                    rows_tags.append({\"tagid\": tagid_counter, \"tag_name\": t[\"tag_name\"], \"weight\": t[\"weight\"]})\n",
    "                    tagid_counter += 1\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.warning(f\"Skipping tags for appid {appid}: {e}\")\n",
    "            continue\n",
    "\n",
    "    game_tag_df = pd.DataFrame(rows_game_tag)\n",
    "    tags_df = pd.DataFrame(rows_tags)\n",
    "\n",
    "    if output_dir:\n",
    "        os.makedirs(output_dir, exist_ok=True)\n",
    "        game_tag_df.to_csv(os.path.join(output_dir, \"game_tag.csv\"), index=False)\n",
    "        tags_df.to_csv(os.path.join(output_dir, \"tags.csv\"), index=False)\n",
    "        logging.info(f\"Saved 'game_tag.csv' ({len(game_tag_df)} rows) to {output_dir}\")\n",
    "        logging.info(f\"Saved 'tags.csv' ({len(tags_df)} rows) to {output_dir}\")\n",
    "\n",
    "    return game_tag_df, tags_df\n",
    "\n",
    "\n",
    "\n",
    "def main():\n",
    "    warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "    logging.info(\"=== Starting splitting process ===\")\n",
    "    D = load_csv_safely(os.path.join(D_PATH, \"merged_master.csv\"))\n",
    "    \n",
    "    media_df = create_media_table(D, output_dir=OUTPUT_PATH)\n",
    "    screenshot_df = create_screenshots_table(D, output_dir=OUTPUT_PATH)\n",
    "    movies_df = create_movies_table(D, output_dir=OUTPUT_PATH)\n",
    "    support_df = create_support_table(D, output_dir=OUTPUT_PATH)\n",
    "    requirements_df = create_requirements_table(D, output_dir=OUTPUT_PATH)\n",
    "    platforms_df = create_platforms_flat(D, output_dir=OUTPUT_PATH)\n",
    "    packages_df = clean_packages(D, output_dir=OUTPUT_PATH)\n",
    "    developer_df = create_developer_tables(D, output_dir=OUTPUT_PATH)\n",
    "    publisher_df = create_publisher_tables(D, output_dir=OUTPUT_PATH)\n",
    "    genres_df = create_genres_flat(D, output_dir=OUTPUT_PATH)\n",
    "    categories_df = create_categories_flat(D, output_dir=OUTPUT_PATH)\n",
    "    tags_df = create_tags_flat(D, output_dir=OUTPUT_PATH)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mediaid</th>\n",
       "      <th>appid</th>\n",
       "      <th>header_image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>https://cdn.akamai.steamstatic.com/steam/apps/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>https://shared.akamai.steamstatic.com/store_it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>https://cdn.akamai.steamstatic.com/steam/apps/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>https://shared.akamai.steamstatic.com/store_it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>https://cdn.akamai.steamstatic.com/steam/apps/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>https://shared.akamai.steamstatic.com/store_it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>https://cdn.akamai.steamstatic.com/steam/apps/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>https://cdn.akamai.steamstatic.com/steam/apps/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>130</td>\n",
       "      <td>https://shared.akamai.steamstatic.com/store_it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>220</td>\n",
       "      <td>https://cdn.akamai.steamstatic.com/steam/apps/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mediaid  appid                                       header_image\n",
       "0        1     10  https://cdn.akamai.steamstatic.com/steam/apps/...\n",
       "1        2     20  https://shared.akamai.steamstatic.com/store_it...\n",
       "2        3     30  https://cdn.akamai.steamstatic.com/steam/apps/...\n",
       "3        4     40  https://shared.akamai.steamstatic.com/store_it...\n",
       "4        5     50  https://cdn.akamai.steamstatic.com/steam/apps/...\n",
       "5        6     60  https://shared.akamai.steamstatic.com/store_it...\n",
       "6        7     70  https://cdn.akamai.steamstatic.com/steam/apps/...\n",
       "7        8     80  https://cdn.akamai.steamstatic.com/steam/apps/...\n",
       "8        9    130  https://shared.akamai.steamstatic.com/store_it...\n",
       "9       10    220  https://cdn.akamai.steamstatic.com/steam/apps/..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/media.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>screenshotid</th>\n",
       "      <th>appid</th>\n",
       "      <th>screenshots_full</th>\n",
       "      <th>screenshots_thumb</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>['https://cdn.akamai.steamstatic.com/steam/app...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/10/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>['https://shared.akamai.steamstatic.com/store_...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/20/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>['https://cdn.akamai.steamstatic.com/steam/app...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/30/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>['https://shared.akamai.steamstatic.com/store_...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/40/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>['https://cdn.akamai.steamstatic.com/steam/app...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/50/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>['https://shared.akamai.steamstatic.com/store_...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/60/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>['https://cdn.akamai.steamstatic.com/steam/app...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/70/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>['https://cdn.akamai.steamstatic.com/steam/app...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/80/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>130</td>\n",
       "      <td>['https://shared.akamai.steamstatic.com/store_...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/130...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>220</td>\n",
       "      <td>['https://cdn.akamai.steamstatic.com/steam/app...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/220...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   screenshotid  appid                                   screenshots_full  \\\n",
       "0             1     10  ['https://cdn.akamai.steamstatic.com/steam/app...   \n",
       "1             2     20  ['https://shared.akamai.steamstatic.com/store_...   \n",
       "2             3     30  ['https://cdn.akamai.steamstatic.com/steam/app...   \n",
       "3             4     40  ['https://shared.akamai.steamstatic.com/store_...   \n",
       "4             5     50  ['https://cdn.akamai.steamstatic.com/steam/app...   \n",
       "5             6     60  ['https://shared.akamai.steamstatic.com/store_...   \n",
       "6             7     70  ['https://cdn.akamai.steamstatic.com/steam/app...   \n",
       "7             8     80  ['https://cdn.akamai.steamstatic.com/steam/app...   \n",
       "8             9    130  ['https://shared.akamai.steamstatic.com/store_...   \n",
       "9            10    220  ['https://cdn.akamai.steamstatic.com/steam/app...   \n",
       "\n",
       "                                   screenshots_thumb  \n",
       "0  https://steamcdn-a.akamaihd.net/steam/apps/10/...  \n",
       "1  https://steamcdn-a.akamaihd.net/steam/apps/20/...  \n",
       "2  https://steamcdn-a.akamaihd.net/steam/apps/30/...  \n",
       "3  https://steamcdn-a.akamaihd.net/steam/apps/40/...  \n",
       "4  https://steamcdn-a.akamaihd.net/steam/apps/50/...  \n",
       "5  https://steamcdn-a.akamaihd.net/steam/apps/60/...  \n",
       "6  https://steamcdn-a.akamaihd.net/steam/apps/70/...  \n",
       "7  https://steamcdn-a.akamaihd.net/steam/apps/80/...  \n",
       "8  https://steamcdn-a.akamaihd.net/steam/apps/130...  \n",
       "9  https://steamcdn-a.akamaihd.net/steam/apps/220...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/screenshots.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieid</th>\n",
       "      <th>appid</th>\n",
       "      <th>movies_max</th>\n",
       "      <th>movies_thumbnail</th>\n",
       "      <th>movies_480</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>20</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>30</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>60</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>70</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>80</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>130</td>\n",
       "      <td>[]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>220</td>\n",
       "      <td>['http://cdn.akamai.steamstatic.com/steam/apps...</td>\n",
       "      <td>https://steamcdn-a.akamaihd.net/steam/apps/904...</td>\n",
       "      <td>http://steamcdn-a.akamaihd.net/steam/apps/904/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   movieid  appid                                         movies_max  \\\n",
       "0        1     10                                                 []   \n",
       "1        2     20                                                 []   \n",
       "2        3     30                                                 []   \n",
       "3        4     40                                                 []   \n",
       "4        5     50                                                 []   \n",
       "5        6     60                                                 []   \n",
       "6        7     70                                                 []   \n",
       "7        8     80                                                 []   \n",
       "8        9    130                                                 []   \n",
       "9       10    220  ['http://cdn.akamai.steamstatic.com/steam/apps...   \n",
       "\n",
       "                                    movies_thumbnail  \\\n",
       "0                                                NaN   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "6                                                NaN   \n",
       "7                                                NaN   \n",
       "8                                                NaN   \n",
       "9  https://steamcdn-a.akamaihd.net/steam/apps/904...   \n",
       "\n",
       "                                          movies_480  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7                                                NaN  \n",
       "8                                                NaN  \n",
       "9  http://steamcdn-a.akamaihd.net/steam/apps/904/...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/movies.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>supportid</th>\n",
       "      <th>appid</th>\n",
       "      <th>support_url</th>\n",
       "      <th>support_email</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>http://steamcommunity.com/app/10</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>50</td>\n",
       "      <td>https://help.steampowered.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>70</td>\n",
       "      <td>http://steamcommunity.com/app/70</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>80</td>\n",
       "      <td>http://steamcommunity.com/app/80</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>https://help.steampowered.com</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>220</td>\n",
       "      <td>http://steamcommunity.com/app/220</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>240</td>\n",
       "      <td>http://steamcommunity.com/app/240</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>400</td>\n",
       "      <td>http://steamcommunity.com/app/400</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>440</td>\n",
       "      <td>http://steamcommunity.com/app/440</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>500</td>\n",
       "      <td>http://steamcommunity.com/app/500</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   supportid  appid                        support_url support_email\n",
       "0          1     10   http://steamcommunity.com/app/10           NaN\n",
       "1          2     50      https://help.steampowered.com           NaN\n",
       "2          3     70   http://steamcommunity.com/app/70           NaN\n",
       "3          4     80   http://steamcommunity.com/app/80           NaN\n",
       "4          5    130      https://help.steampowered.com           NaN\n",
       "5          6    220  http://steamcommunity.com/app/220           NaN\n",
       "6          7    240  http://steamcommunity.com/app/240           NaN\n",
       "7          8    400  http://steamcommunity.com/app/400           NaN\n",
       "8          9    440  http://steamcommunity.com/app/440           NaN\n",
       "9         10    500  http://steamcommunity.com/app/500           NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/support.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reqid</th>\n",
       "      <th>appid</th>\n",
       "      <th>os</th>\n",
       "      <th>type</th>\n",
       "      <th>requirements</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>windows</td>\n",
       "      <td>minimum</td>\n",
       "      <td>500 mhz processor, 96mb ram, 16mb video card, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>windows</td>\n",
       "      <td>recommended</td>\n",
       "      <td>800 mhz processor, 128mb ram, 32mb+ video card...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>mac</td>\n",
       "      <td>minimum</td>\n",
       "      <td>OS X Snow Leopard 10.6.3, 1GB RAM, 4GB Hard Dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>linux</td>\n",
       "      <td>minimum</td>\n",
       "      <td>Linux Ubuntu 12.04, Dual-core from Intel or AM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>20</td>\n",
       "      <td>windows</td>\n",
       "      <td>minimum</td>\n",
       "      <td>500 mhz processor, 96mb ram, 16mb video card, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>windows</td>\n",
       "      <td>recommended</td>\n",
       "      <td>800 mhz processor, 128mb ram, 32mb+ video card...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>20</td>\n",
       "      <td>mac</td>\n",
       "      <td>minimum</td>\n",
       "      <td>OS X Snow Leopard 10.6.3, 1GB RAM, 4GB Hard Dr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>linux</td>\n",
       "      <td>minimum</td>\n",
       "      <td>Linux Ubuntu 12.04, Dual-core from Intel or AM...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>30</td>\n",
       "      <td>windows</td>\n",
       "      <td>minimum</td>\n",
       "      <td>500 mhz processor, 96mb ram, 16mb video card, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>30</td>\n",
       "      <td>windows</td>\n",
       "      <td>recommended</td>\n",
       "      <td>800 mhz processor, 128mb ram, 32mb+ video card...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reqid  appid       os         type  \\\n",
       "0      1     10  windows      minimum   \n",
       "1      2     10  windows  recommended   \n",
       "2      3     10      mac      minimum   \n",
       "3      4     10    linux      minimum   \n",
       "4      5     20  windows      minimum   \n",
       "5      6     20  windows  recommended   \n",
       "6      7     20      mac      minimum   \n",
       "7      8     20    linux      minimum   \n",
       "8      9     30  windows      minimum   \n",
       "9     10     30  windows  recommended   \n",
       "\n",
       "                                        requirements  \n",
       "0  500 mhz processor, 96mb ram, 16mb video card, ...  \n",
       "1  800 mhz processor, 128mb ram, 32mb+ video card...  \n",
       "2  OS X Snow Leopard 10.6.3, 1GB RAM, 4GB Hard Dr...  \n",
       "3  Linux Ubuntu 12.04, Dual-core from Intel or AM...  \n",
       "4  500 mhz processor, 96mb ram, 16mb video card, ...  \n",
       "5  800 mhz processor, 128mb ram, 32mb+ video card...  \n",
       "6  OS X Snow Leopard 10.6.3, 1GB RAM, 4GB Hard Dr...  \n",
       "7  Linux Ubuntu 12.04, Dual-core from Intel or AM...  \n",
       "8  500 mhz processor, 96mb ram, 16mb video card, ...  \n",
       "9  800 mhz processor, 128mb ram, 32mb+ video card...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/requirements.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>platid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid  platid\n",
       "0     10       1\n",
       "1     20       2\n",
       "2     30       3\n",
       "3     40       4\n",
       "4     50       5\n",
       "5     60       6\n",
       "6     70       7\n",
       "7     80       8\n",
       "8    130       9\n",
       "9    220      10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/game_platform.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>platid</th>\n",
       "      <th>windows</th>\n",
       "      <th>linux</th>\n",
       "      <th>mac</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   platid  windows  linux   mac\n",
       "0       1     True   True  True\n",
       "1       2     True   True  True\n",
       "2       3     True   True  True\n",
       "3       4     True   True  True\n",
       "4       5     True   True  True\n",
       "5       6     True   True  True\n",
       "6       7     True   True  True\n",
       "7       8     True   True  True\n",
       "8       9     True   True  True\n",
       "9      10     True   True  True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/platforms.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>packid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid  packid\n",
       "0     10       1\n",
       "1     20       2\n",
       "2     30       3\n",
       "3     40       4\n",
       "4     50       5\n",
       "5     60       6\n",
       "6     70       7\n",
       "7     80       8\n",
       "8    130       9\n",
       "9    220      10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/game_package.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>packid</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Buy Counter-Strike</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Buy Team Fortress Classic</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Buy Day of Defeat</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Buy Deathmatch Classic</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Buy Half-Life: Opposing Force</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Buy Ricochet</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Buy Half-Life</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Buy Counter-Strike: Condition Zero</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Buy Half-Life: Blue Shift</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Buy Half-Life 2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   packid                               title description\n",
       "0       1                  Buy Counter-Strike         NaN\n",
       "1       2           Buy Team Fortress Classic         NaN\n",
       "2       3                   Buy Day of Defeat         NaN\n",
       "3       4              Buy Deathmatch Classic         NaN\n",
       "4       5       Buy Half-Life: Opposing Force         NaN\n",
       "5       6                        Buy Ricochet         NaN\n",
       "6       7                       Buy Half-Life         NaN\n",
       "7       8  Buy Counter-Strike: Condition Zero         NaN\n",
       "8       9           Buy Half-Life: Blue Shift         NaN\n",
       "9      10                     Buy Half-Life 2         NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/packages.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>packid</th>\n",
       "      <th>sub_text</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Counter-Strike: Condition Zero - $9.99</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Counter-Strike - Commercial License - $9.99</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Team Fortress Classic - $4.99</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Day of Defeat - $4.99</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Day of Defeat - Commercial License - $4.99</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4</td>\n",
       "      <td>Deathmatch Classic - $4.99</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>Half-Life: Opposing Force - $4.99</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Ricochet - $4.99</td>\n",
       "      <td>4.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>7</td>\n",
       "      <td>Half-Life - $9.99</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>Half-Life - Commercial License - $9.99</td>\n",
       "      <td>9.99</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   packid                                     sub_text  price\n",
       "0       1       Counter-Strike: Condition Zero - $9.99   9.99\n",
       "1       1  Counter-Strike - Commercial License - $9.99   9.99\n",
       "2       2                Team Fortress Classic - $4.99   4.99\n",
       "3       3                        Day of Defeat - $4.99   4.99\n",
       "4       3   Day of Defeat - Commercial License - $4.99   4.99\n",
       "5       4                   Deathmatch Classic - $4.99   4.99\n",
       "6       5            Half-Life: Opposing Force - $4.99   4.99\n",
       "7       6                             Ricochet - $4.99   4.99\n",
       "8       7                            Half-Life - $9.99   9.99\n",
       "9       7       Half-Life - Commercial License - $9.99   9.99"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/sub_package.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>devid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid  devid\n",
       "0     10      1\n",
       "1     20      2\n",
       "2     30      3\n",
       "3     40      4\n",
       "4     50      5\n",
       "5     60      6\n",
       "6     70      7\n",
       "7     80      8\n",
       "8    130      9\n",
       "9    220     10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/game_developer.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>devid</th>\n",
       "      <th>developer_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Gearbox Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Gearbox Software</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   devid    developer_name\n",
       "0      1             Valve\n",
       "1      2             Valve\n",
       "2      3             Valve\n",
       "3      4             Valve\n",
       "4      5  Gearbox Software\n",
       "5      6             Valve\n",
       "6      7             Valve\n",
       "7      8             Valve\n",
       "8      9  Gearbox Software\n",
       "9     10             Valve"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/developers.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>pubid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid  pubid\n",
       "0     10      1\n",
       "1     20      2\n",
       "2     30      3\n",
       "3     40      4\n",
       "4     50      5\n",
       "5     60      6\n",
       "6     70      7\n",
       "7     80      8\n",
       "8    130      9\n",
       "9    220     10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/game_publisher.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pubid</th>\n",
       "      <th>publisher_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Valve</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pubid publisher_name\n",
       "0      1          Valve\n",
       "1      2          Valve\n",
       "2      3          Valve\n",
       "3      4          Valve\n",
       "4      5          Valve\n",
       "5      6          Valve\n",
       "6      7          Valve\n",
       "7      8          Valve\n",
       "8      9          Valve\n",
       "9     10          Valve"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/publishers.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>genreid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid  genreid\n",
       "0     10        1\n",
       "1     20        2\n",
       "2     30        3\n",
       "3     40        4\n",
       "4     50        5\n",
       "5     60        6\n",
       "6     70        7\n",
       "7     80        8\n",
       "8    130        9\n",
       "9    220       10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/game_genre.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>genreid</th>\n",
       "      <th>genre_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>['Action']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>['Action']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>['Action']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>['Action']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>['Action']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>['Action']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>['Action']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>['Action']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>['Action']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>['Action']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   genreid  genre_name\n",
       "0        1  ['Action']\n",
       "1        2  ['Action']\n",
       "2        3  ['Action']\n",
       "3        4  ['Action']\n",
       "4        5  ['Action']\n",
       "5        6  ['Action']\n",
       "6        7  ['Action']\n",
       "7        8  ['Action']\n",
       "8        9  ['Action']\n",
       "9       10  ['Action']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/genres.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>catid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>130</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>220</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid  catid\n",
       "0     10      1\n",
       "1     20      2\n",
       "2     30      3\n",
       "3     40      4\n",
       "4     50      5\n",
       "5     60      6\n",
       "6     70      7\n",
       "7     80      8\n",
       "8    130      9\n",
       "9    220     10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/game_category.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>catid</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Multi-player, Online Multi-Player, Local Multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Multi-player, Online Multi-Player, Local Multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Multi-player, Valve Anti-Cheat enabled, Family...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Multi-player, Online Multi-Player, Local Multi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Single-player, Multi-player, Valve Anti-Cheat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Multi-player, Online Multi-Player, Valve Anti-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Single-player, Multi-player, Online Multi-Play...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Single-player, Multi-player, Valve Anti-Cheat ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Single-player, Remote Play Together, Family Sh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Single-player, Steam Achievements, Steam Tradi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   catid                                               name\n",
       "0      1  Multi-player, Online Multi-Player, Local Multi...\n",
       "1      2  Multi-player, Online Multi-Player, Local Multi...\n",
       "2      3  Multi-player, Valve Anti-Cheat enabled, Family...\n",
       "3      4  Multi-player, Online Multi-Player, Local Multi...\n",
       "4      5  Single-player, Multi-player, Valve Anti-Cheat ...\n",
       "5      6  Multi-player, Online Multi-Player, Valve Anti-...\n",
       "6      7  Single-player, Multi-player, Online Multi-Play...\n",
       "7      8  Single-player, Multi-player, Valve Anti-Cheat ...\n",
       "8      9  Single-player, Remote Play Together, Family Sh...\n",
       "9     10  Single-player, Steam Achievements, Steam Tradi..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/categories.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>appid</th>\n",
       "      <th>tagid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   appid  tagid\n",
       "0     10      1\n",
       "1     10      2\n",
       "2     10      3\n",
       "3     10      4\n",
       "4     10      5\n",
       "5     10      6\n",
       "6     10      7\n",
       "7     10      8\n",
       "8     10      9\n",
       "9     10     10"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/game_tag.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV loaded successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tagid</th>\n",
       "      <th>tag_name</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Action</td>\n",
       "      <td>5472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>FPS</td>\n",
       "      <td>4897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Multiplayer</td>\n",
       "      <td>3444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Shooter</td>\n",
       "      <td>3394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Classic</td>\n",
       "      <td>2822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>Team-Based</td>\n",
       "      <td>1896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>First-Person</td>\n",
       "      <td>1736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Competitive</td>\n",
       "      <td>1631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Tactical</td>\n",
       "      <td>1370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1990's</td>\n",
       "      <td>1231</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tagid      tag_name  weight\n",
       "0      1        Action    5472\n",
       "1      2           FPS    4897\n",
       "2      3   Multiplayer    3444\n",
       "3      4       Shooter    3394\n",
       "4      5       Classic    2822\n",
       "5      6    Team-Based    1896\n",
       "6      7  First-Person    1736\n",
       "7      8   Competitive    1631\n",
       "8      9      Tactical    1370\n",
       "9     10        1990's    1231"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "csv_path = 'C:/Users/zalma/split/tags.csv'\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    print(\"CSV loaded successfully!\")\n",
    "    display(df.head(10))\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: The file was not found at {csv_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3013528029.py, line 250)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 250\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31m'''\u001b[39m\n    ^\n\u001b[31mIndentationError\u001b[39m\u001b[31m:\u001b[39m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Nem használt de fontos függvények, majd visszarakom őket ha a merge már rendben lesz teljesen.\n",
    "\"\"\"\n",
    "# ======== NAME MATCHING FUNCTION ========\n",
    "def analyze_name_matches(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Ellenőrzi a 'name' mezőkben az egyezéseket az A, B, C források között.\n",
    "    Külön vizsgálja a pontos egyezést és a formai (normalizált) egyezést.\n",
    "    \"\"\"\n",
    "\n",
    "    def normalize_name(name):\n",
    "        if pd.isna(name):\n",
    "            return \"\"\n",
    "        return \"\".join(c.lower() for c in name if c.isalnum())\n",
    "\n",
    "    for col in [\"name_a\", \"name_b\", \"name_c\"]:\n",
    "        if col in df.columns:\n",
    "            df[f\"{col}_norm\"] = df[col].apply(normalize_name)\n",
    "\n",
    "    exact_matches = (df.get(\"name_a\") == df.get(\"name_b\")) & (\n",
    "        df.get(\"name_b\") == df.get(\"name_c\")\n",
    "    )\n",
    "    logging.info(f\"Pontos névegyezések száma minden forrásban: {exact_matches.sum()}\")\n",
    "\n",
    "    partial_matches = (df.get(\"name_a_norm\") == df.get(\"name_b_norm\")) & (\n",
    "        df.get(\"name_b_norm\") == df.get(\"name_c_norm\")\n",
    "    )\n",
    "    logging.info(\n",
    "        f\"Formaileg egyező nevek száma minden forrásban: {partial_matches.sum()}\"\n",
    "    )\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# ======== MULTI-SOURCE ATTRIBUTE ANALYSIS ========\n",
    "def analyze_multi_source_attribute(df: pd.DataFrame, attr: str):\n",
    "    \"\"\"\n",
    "    Vizsgálja egy adott attribútum ('genre', 'category', 'language', stb.) értékeit\n",
    "    az A, B, C forrásokban, és logolja az érvényes értékek számát,\n",
    "    az egyedi értékek számát és a teljes egyezést.\n",
    "    \"\"\"\n",
    "    cols = [f\"{attr}_a\", f\"{attr}_b\", f\"{attr}_c\"]\n",
    "    for col in cols:\n",
    "        if col not in df.columns:\n",
    "            df[col] = pd.NA\n",
    "\n",
    "    notna_counts = df[cols].notna().sum()\n",
    "    logging.info(f\"{attr} - érvényes értékek száma forrásonként:\\n{notna_counts}\")\n",
    "\n",
    "    unique_values = {col: df[col].dropna().unique() for col in cols}\n",
    "    for col, values in unique_values.items():\n",
    "        logging.info(f\"{col} - egyedi értékek száma: {len(values)}\")\n",
    "\n",
    "    all_equal = (df[cols[0]] == df[cols[1]]) & (df[cols[1]] == df[cols[2]])\n",
    "    logging.info(f\"{attr} - pontos egyezések minden forrásban: {all_equal.sum()}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def summarize_dataset(df: pd.DataFrame, name: str, block_size: int = 5):\n",
    "    \"\"\"\n",
    "    Részletes összegzést készít egy DataFrame-ről:\n",
    "    sorok száma, oszlopok száma, memóriahasználat, oszlopok típusai.\n",
    "    \"\"\"\n",
    "    if df.empty:\n",
    "        logging.info(f\"{name} dataset is empty!\")\n",
    "        return\n",
    "\n",
    "    logging.info(f\"=== Summary of {name} dataset ===\")\n",
    "    logging.info(f\"Rows: {len(df)}, Columns: {len(df.columns)}\")\n",
    "    logging.info(f\"Memory usage: {df.memory_usage(deep=True).sum() / 1024**2:.2f} MB\")\n",
    "\n",
    "    col_types = [f\"{col}: {dtype}\" for col, dtype in df.dtypes.items()]\n",
    "\n",
    "    for i in range(0, len(col_types), block_size):\n",
    "        block = col_types[i : i + block_size]\n",
    "        logging.info(\" | \".join(block))\n",
    "\n",
    "    logging.info(\"==============================\")\n",
    "\n",
    "\n",
    "def inspect_game_in_all_sources(merged_df: pd.DataFrame, appid: str):\n",
    "    \"\"\"\n",
    "    Megmutatja a játék adatait, ami mindhárom forrásban szerepel.\n",
    "    merged_df: a merge_sources után létrejött DataFrame\n",
    "    appid: az ellenőrizni kívánt AppID\n",
    "    \"\"\"\n",
    "    # Csak a megadott appid sorainak kiszedése\n",
    "    game_row = merged_df[merged_df[\"appid\"] == str(appid)]\n",
    "\n",
    "    if game_row.empty:\n",
    "        return\n",
    "\n",
    "    # Kinyomtatjuk az összes oszlopot\n",
    "    pd.set_option(\"display.max_columns\", None)  # minden oszlop látszik\n",
    "    pd.set_option(\"display.width\", 200)  # ne törjön sorokra\n",
    "    print(game_row.T)  # transzponáljuk, hogy oszloponként lássuk\n",
    "\n",
    "    # Optionálisan visszaadjuk DataFrame-ként is\n",
    "    return game_row\n",
    "\n",
    "\n",
    "# ======== VISUALIZATION FUNCTIONS ========\n",
    "def plot_release_year_histograms(df_a, df_b, df_c, output_path):\n",
    "    \"\"\"\n",
    "    Három hisztogramot készít, amelyek az A, B, C datasetek\n",
    "    játékainak megjelenési év szerinti megoszlását mutatják.\n",
    "    Az elkészült ábra mentésre kerül a merge mappába.\n",
    "    \"\"\"\n",
    "\n",
    "    import re\n",
    "    import matplotlib.pyplot as plt\n",
    "    import pandas as pd\n",
    "\n",
    "    def extract_year(date_str):\n",
    "        \"\"\"Próbál többféle dátumformátumból évet kinyerni.\"\"\"\n",
    "        if not isinstance(date_str, str) or not date_str.strip():\n",
    "            return None\n",
    "\n",
    "        date_str = date_str.strip()\n",
    "\n",
    "        # Ismert dátumformátumok kipróbálása\n",
    "        for fmt in (\"%b %d, %Y\", \"%Y-%m-%d\", \"%d %b %Y\", \"%Y\"):\n",
    "            try:\n",
    "                dt = pd.to_datetime(date_str, format=fmt, errors=\"raise\")\n",
    "                return dt.year\n",
    "            except Exception:\n",
    "                continue\n",
    "\n",
    "        # Ha nem ismerte fel, keressünk 4 egymást követő számjegyet (év)\n",
    "        match = re.search(r\"(19|20)\\d{2}\", date_str)\n",
    "        if match:\n",
    "            return int(match.group(0))\n",
    "\n",
    "        return None\n",
    "\n",
    "    # === Évek kinyerése mindhárom datasetből ===\n",
    "    for df in [df_a, df_b, df_c]:\n",
    "        if \"release_date\" in df.columns:\n",
    "            df[\"year\"] = df[\"release_date\"].apply(extract_year)\n",
    "        else:\n",
    "            df[\"year\"] = None\n",
    "\n",
    "    # Szűrés érvényes évre\n",
    "    df_a = df_a.dropna(subset=[\"year\"])\n",
    "    df_b = df_b.dropna(subset=[\"year\"])\n",
    "    df_c = df_c.dropna(subset=[\"year\"])\n",
    "\n",
    "    # === Rajzolás ===\n",
    "    plt.figure(figsize=(15, 10))\n",
    "\n",
    "    # A dataset\n",
    "    plt.subplot(3, 1, 1)\n",
    "    df_a[\"year\"].value_counts().sort_index().plot(kind=\"bar\", color=\"skyblue\")\n",
    "    plt.title(\"A forrás – játékok száma évenként\")\n",
    "    plt.xlabel(\"Év\")\n",
    "    plt.ylabel(\"Darabszám\")\n",
    "\n",
    "    # B dataset\n",
    "    plt.subplot(3, 1, 2)\n",
    "    df_b[\"year\"].value_counts().sort_index().plot(kind=\"bar\", color=\"lightgreen\")\n",
    "    plt.title(\"B forrás – játékok száma évenként\")\n",
    "    plt.xlabel(\"Év\")\n",
    "    plt.ylabel(\"Darabszám\")\n",
    "\n",
    "    # C dataset\n",
    "    plt.subplot(3, 1, 3)\n",
    "    df_c[\"year\"].value_counts().sort_index().plot(kind=\"bar\", color=\"salmon\")\n",
    "    plt.title(\"C forrás – játékok száma évenként\")\n",
    "    plt.xlabel(\"Év\")\n",
    "    plt.ylabel(\"Darabszám\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # === Mentés és logolás ===\n",
    "    output_file = os.path.join(output_path, \"release_year_histograms.png\")\n",
    "    plt.savefig(output_file, dpi=300)\n",
    "    plt.close()\n",
    "    logging.info(f\"Hisztogram-összesítés mentve: {output_file}\")\n",
    "\n",
    "\n",
    "# ======== HELPER FUNCTIONS ========\n",
    "\n",
    "\n",
    "def venn_table(a: pd.DataFrame, b: pd.DataFrame, c: pd.DataFrame, columns: list):\n",
    "    \"\"\"\n",
    "    Készít egy elemszámos Venn-táblát az A/B/C forrásokhoz.\n",
    "    Figyelembe veszi a 'genres' vagy többlépcsős oszlopokat is.\n",
    "    \"\"\"\n",
    "\n",
    "    def value_set(df, col):\n",
    "        if col not in df.columns:\n",
    "            return set()\n",
    "        s = df[col].dropna()\n",
    "        all_values = set()\n",
    "        for val in s:\n",
    "            if isinstance(val, str):\n",
    "                # Ha listaszerű string, pl. \"['Action', 'Free to Play']\"\n",
    "                if val.startswith(\"[\") and val.endswith(\"]\"):\n",
    "                    try:\n",
    "                        val_list = eval(val)  # biztonságos, ha kontrollált adatok\n",
    "                        all_values.update([str(v) for v in val_list])\n",
    "                    except:\n",
    "                        all_values.add(val)\n",
    "                else:\n",
    "                    # \";\" vagy \",\" elválasztás esetén\n",
    "                    for v in re.split(r\"[;,]\", val):\n",
    "                        all_values.add(v.strip())\n",
    "            else:\n",
    "                all_values.add(str(val))\n",
    "        return all_values\n",
    "\n",
    "    venn_data = {}\n",
    "    for col in columns:\n",
    "        set_a = value_set(a, col)\n",
    "        set_b = value_set(b, col)\n",
    "        set_c = value_set(c, col)\n",
    "\n",
    "        venn_data[col] = {\n",
    "            \"A_only\": len(set_a - set_b - set_c),\n",
    "            \"B_only\": len(set_b - set_a - set_c),\n",
    "            \"C_only\": len(set_c - set_a - set_b),\n",
    "            \"A&B\": len(set_a & set_b - set_c),\n",
    "            \"A&C\": len(set_a & set_c - set_b),\n",
    "            \"B&C\": len(set_b & set_c - set_a),\n",
    "            \"A&B&C\": len(set_a & set_b & set_c),\n",
    "        }\n",
    "\n",
    "    return pd.DataFrame.from_dict(venn_data, orient=\"index\")\n",
    "\n",
    "\n",
    "def plot_venn_table(\n",
    "    venn_df: pd.DataFrame, output_path: str, filename: str = \"venn_table.png\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Vizualizálja a Venn-táblát színes hőtérképként (heatmap).\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(12, max(4, len(venn_df) * 0.5)))\n",
    "    plt.imshow(venn_df, cmap=\"YlGnBu\", aspect=\"auto\")\n",
    "    plt.colorbar(label=\"Darabszám\")\n",
    "\n",
    "    plt.xticks(range(len(venn_df.columns)), venn_df.columns, rotation=45)\n",
    "    plt.yticks(range(len(venn_df)), venn_df.index)\n",
    "    plt.title(\"Elemszámos Venn diagram táblázatként\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(os.path.join(output_path, filename), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "        '''\n",
    "    # ======== RAW SOURCES EXPORT ========\n",
    "    os.makedirs(OUTPUT_PATH, exist_ok=True)\n",
    "    a.to_csv(os.path.join(OUTPUT_PATH, \"source_A_raw.csv\"), index=False, encoding=\"utf-8\")\n",
    "    b.to_csv(os.path.join(OUTPUT_PATH, \"source_B_raw.csv\"), index=False, encoding=\"utf-8\")\n",
    "    c.to_csv(os.path.join(OUTPUT_PATH, \"source_C_raw.csv\"), index=False, encoding=\"utf-8\")\n",
    "    logging.info(\"Raw source CSVs saved: source_A_raw.csv, source_B_raw.csv, source_C_raw.csv\")\n",
    "    '''\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    '''\n",
    "    summarize_dataset(a, \"A\")\n",
    "    summarize_dataset(b, \"B\")\n",
    "    summarize_dataset(c, \"C\")\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    logging.info(f\"Rows per source before merge: A={len(a)}, B={len(b)}, C={len(c)}\")\n",
    "    '''\n",
    "\n",
    "    \n",
    "    '''\n",
    "    set_a = set(a[\"appid\"])\n",
    "    set_b = set(b[\"appid\"])\n",
    "    set_c = set(c[\"appid\"])\n",
    "\n",
    "    only_a = len(set_a - set_b - set_c)\n",
    "    only_b = len(set_b - set_a - set_c)\n",
    "    only_c = len(set_c - set_a - set_b)\n",
    "    a_b = len(set_a & set_b - set_c)\n",
    "    a_c = len(set_a & set_c - set_b)\n",
    "    b_c = len(set_b & set_c - set_a)\n",
    "    a_b_c = len(set_a & set_b & set_c)\n",
    "\n",
    "    logging.info(f\"Unique by source: A={only_a}, B={only_b}, C={only_c}\")\n",
    "    logging.info(f\"Overlaps: A&B={a_b}, A&C={a_c}, B&C={b_c}, A&B&C={a_b_c}\")\n",
    "    '''\n",
    "\n",
    "    \n",
    "\n",
    "    '''\n",
    "    # ======== VENN-DIAGRAM ========\n",
    "    set_a = set(a[\"appid\"].astype(str))\n",
    "    set_b = set(b[\"appid\"].astype(str))\n",
    "    set_c = set(c[\"appid\"].astype(str))\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    venn3([set_a, set_b, set_c], set_labels=(\"A\", \"B\", \"C\"))\n",
    "    plt.title(\"AppID átfedések három forrás között\")\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, \"venn_appid.png\"), dpi=300)\n",
    "    plt.close()\n",
    "\n",
    "    # ======== OVERLAPS BY YEAR (GANTT-LIKE) ========\n",
    "    plt.figure(figsize=(10, 4))\n",
    "\n",
    "    datasets = [\n",
    "        (a, \"A\", \"cornflowerblue\"),\n",
    "        (b, \"B\", \"mediumseagreen\"),\n",
    "        (c, \"C\", \"orchid\"),\n",
    "    ]\n",
    "\n",
    "    for i, (df, label, color) in enumerate(datasets):\n",
    "        release_col = next(\n",
    "            (col for col in df.columns if \"release\" in col and \"date\" in col), None\n",
    "        )\n",
    "\n",
    "        if release_col:\n",
    "            if label == \"B\":\n",
    "                df[\"release_year\"] = pd.to_datetime(df[release_col], errors=\"coerce\")\n",
    "                if df[\"release_year\"].isna().mean() > 0.5:\n",
    "                    df[\"release_year\"] = pd.to_datetime(\n",
    "                        df[release_col].str.strip(), format=\"%b %d, %Y\", errors=\"coerce\"\n",
    "                    )\n",
    "            else:\n",
    "                df[\"release_year\"] = pd.to_datetime(df[release_col], errors=\"coerce\")\n",
    "\n",
    "            df[\"release_year\"] = df[\"release_year\"].dt.year\n",
    "            df = df.dropna(subset=[\"release_year\"])\n",
    "\n",
    "            if not df.empty:\n",
    "                min_year = int(df[\"release_year\"].min())\n",
    "                max_year = int(df[\"release_year\"].max())\n",
    "                plt.barh(\n",
    "                    y=i,\n",
    "                    width=max_year - min_year,\n",
    "                    left=min_year,\n",
    "                    height=0.4,\n",
    "                    color=color,\n",
    "                    alpha=0.7,\n",
    "                    label=label,\n",
    "                )\n",
    "            else:\n",
    "                print(f\" {label} forrásban nincs érvényes dátum!\")\n",
    "        else:\n",
    "            print(f\" {label} forrásban nem található dátummező!\")\n",
    "\n",
    "    plt.yticks(range(len(datasets)), [label for _, label, _ in datasets])\n",
    "    plt.xlabel(\"Kiadási év\")\n",
    "    plt.title(\"Játékok időbeli lefedettsége az A, B, C forrásokban (Gantt-szerű ábra)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(OUTPUT_PATH, \"release_years_gantt.png\"), dpi=300)\n",
    "    plt.close()\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    # ======== CHECKING FOR DUPLICATE APPIDS ========\n",
    "    dupes = merged[merged.duplicated(\"appid\", keep=False)].sort_values(\"appid\")\n",
    "    if not dupes.empty:\n",
    "        dupes_file = os.path.join(OUTPUT_PATH, \"duplicate_appid_records.csv\")\n",
    "        dupes.to_csv(dupes_file, index=False, encoding=\"utf-8\")\n",
    "        logging.info(\n",
    "            f\"{len(dupes)} duplikált AppID rekord található, mentve: {dupes_file}\"\n",
    "        )\n",
    "    else:\n",
    "        logging.info(\"Nincs duplikált AppID a merge után.\")\n",
    "    '''\n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO6q1IaRT88/NmyZgKb44yw",
   "mount_file_id": "1-2PN27SNYh5xNK4Ec8WdXpfCSqfK9dOs",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
